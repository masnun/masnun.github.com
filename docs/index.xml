<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>masnun.rocks()</title>
    <link>http://masnun.rocks/index.xml</link>
    <description>Recent content on masnun.rocks()</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 20 Mar 2017 22:43:59 +0600</lastBuildDate>
    <atom:link href="http://masnun.rocks/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Django Admin: Expensive COUNT(*) Queries</title>
      <link>http://masnun.rocks/2017/03/20/django-admin-expensive-count-all-queries/</link>
      <pubDate>Mon, 20 Mar 2017 22:43:59 +0600</pubDate>
      
      <guid>http://masnun.rocks/2017/03/20/django-admin-expensive-count-all-queries/</guid>
      <description>

&lt;p&gt;If you are a Django developer, it is very likely that you use the Django Admin regularly. And if you have maintained a website with a huge amount of data, you probably already know that Django Admin can become very slow when the database table gets so large. If you log the SQL queries (either using Django logging or using Django Debug Toolbar), you would notice a very expensive
SQL query, something like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-SQL&#34;&gt;SELECT COUNT(*) AS &amp;quot;__count&amp;quot; FROM &amp;quot;table_name&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In the default settings, you will actually notice this query twice. If you use Django Debug Toolbar, it will tell you that the query was duplicated 2 times.&lt;/p&gt;

&lt;h3 id=&#34;issue-1&#34;&gt;Issue - 1&lt;/h3&gt;

&lt;p&gt;By default &lt;code&gt;ModelAdmin&lt;/code&gt; has &lt;code&gt;show_full_result_count = True&lt;/code&gt; which shows the full result count in the admin interface. This is the source of one of the &lt;code&gt;count(*)&lt;/code&gt; queries.&lt;/p&gt;

&lt;p&gt;To fix that, we just need to set this on our &lt;code&gt;ModelAdmin&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Python&#34;&gt;show_full_result_count = False
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;issue-2&#34;&gt;Issue - 2&lt;/h3&gt;

&lt;p&gt;Even after switching &lt;code&gt;show_full_result_count&lt;/code&gt; off, we are still noticing a &lt;code&gt;count(*)&lt;/code&gt; query in the log. It&amp;rsquo;s because the Django Paginator does a count itself.&lt;/p&gt;

&lt;p&gt;The solution is to somehow bypass the expensive query while still returning a number so the pagination works as expected. We can cache the count value or even run raw SQL query find an approximate value through a rather inexpensive lookup somewhere else.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s a quick example of a paginator that runs the expensive query once and then caches the results:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Python&#34;&gt;from django.core.paginator import Paginator
from django.core.cache import cache

# Modified version of a GIST I found in a SO thread
class CachingPaginator(Paginator):
    def _get_count(self):

        if not hasattr(self, &amp;quot;_count&amp;quot;):
            self._count = None

        if self._count is None:
            try:
                key = &amp;quot;adm:{0}:count&amp;quot;.format(hash(self.object_list.query.__str__()))
                self._count = cache.get(key, -1)
                if self._count == -1:
                    self._count = super().count
                    cache.set(key, self._count, 3600)

            except:
                self._count = len(self.object_list)
        return self._count

    count = property(_get_count)

    
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now on our &lt;code&gt;ModelAdmin&lt;/code&gt; we just need to use this paginator.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Python&#34;&gt;paginator = CachingPaginator
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Once we have done that, it will be slow when we first time load the page and it will be faster afterwards. We can also fetch and cache this value from time to time. This solution might not get us the exact count and thus mess up pagination sometimes but in most cases that would not be much
of a problem.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Learning Elixir: First Impressions</title>
      <link>http://masnun.rocks/2017/02/18/learning-elixir-first-impressions/</link>
      <pubDate>Sat, 18 Feb 2017 12:12:47 +0600</pubDate>
      
      <guid>http://masnun.rocks/2017/02/18/learning-elixir-first-impressions/</guid>
      <description>

&lt;p&gt;Elixir is a new programming language that I have become very fond of. It is a dynamic, functional programming language built on top of the Erlang VM (BEAM). Ever wondered why almost all the telecom companies around the world use Erlang for their telephony systems? There has to be a reason, right? Before we dive into Elixir, it is essential to discuss a bit about Erlang and the VM (BEAM).&lt;/p&gt;

&lt;h3 id=&#34;a-brief-intro-to-erlang&#34;&gt;A brief intro to Erlang&lt;/h3&gt;

&lt;p&gt;Erlang was developed by Ericsson and was written in Prolog in it&amp;rsquo;s early days. Erlang proved it&amp;rsquo;s worth as a suitable language that can be used in telephone exchanges but the prolog interpreter was
too slow for that job. So a group inside Ericsson developed the BEAM VM that compiles Erlang to C. The effort was very successful and in 1998 Ericsson launched their new AXD301 switch - which had  over a million lines of Erlang code. Thanks to the reliability and stability of the new VM, the system managed &amp;ldquo;nine 9s&amp;rdquo; uptime. According to &lt;a href=&#34;https://en.wikipedia.org/wiki/High_availability#Percentage_calculation&#34;&gt;this Wikipedia article&lt;/a&gt;, that means less than 31.5569 milliseconds downtime per year. However, Ericsson banned Erlang in it&amp;rsquo;s products because it was &amp;ldquo;proprietary&amp;rdquo;. This made Armstrong, the creator of the language and other associates leave Ericsson. And the implementation was open sourced at the end of the year. Ericsson eventually lifted that ban and rehired Armstrong back in 2004.&lt;/p&gt;

&lt;p&gt;Telephone exchanges need very stable and reliable systems with massive uptime. Erlang provided that. The Erlang VM also features hot code reloading - so you don&amp;rsquo;t have to restart your software to load new codes. No restart - no downtime.&lt;/p&gt;

&lt;p&gt;Concurrency is another very strong feat of Erlang. In the telcos, it&amp;rsquo;s very important to be able to handle a lot of concurrent operations at a time. Erlang really excels at that - millions of concurrent connections yet no downtime. That&amp;rsquo;s something, no?&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;If somebody came to me and wanted to pay me a lot of money to build a large scale message handling system that really had to be up all the time, could never afford to go down for years at a time, I would unhesitatingly choose Erlang to build it in.&lt;br /&gt;
&lt;br/&gt;
&amp;ndash; Tim Bray, Director of Web Technologies, Sun Microsystems in OSCON, July 2008&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Erlang comes with the OTP framework which includes some ready to use components and design patterns to follow for building robust Erlang applications. Erlang is often called &amp;ldquo;Erlang/OTP&amp;rdquo; because of this accompanying framework.&lt;/p&gt;

&lt;p&gt;We have seen the battle proven track record of Erlang in Telcos. But that&amp;rsquo;s not all. Erlang has been adopted in modern day applications too. For example WhatsApp used Erlang to build and scale their messaging platform across millions of their users. Facebook also used Erlang for their chat infrastructure.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;If Java is &amp;lsquo;write once, run anywhere&amp;rsquo;, then Erlang is &amp;lsquo;write once, run forever&amp;rsquo;.
&lt;br/&gt;&lt;br/&gt;
&amp;ndash; Joe Armstrong, Creator of Erlang, 2013&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;why-do-we-need-elixir&#34;&gt;Why do we need Elixir?&lt;/h3&gt;

&lt;p&gt;So Erlang is successful and battle tested, matured over the last 25 years or so, then why do we need a new language? Well, Erlang itself is very robust, scalable, matured but the syntax of the language was not easily approachable for me. And I believe in that context, I am not alone.&lt;/p&gt;

&lt;p&gt;On the other hand, Elixir as a language is relatively much easier to start and grasp. I, for example, have never really felt motivated enough to learn Erlang. But Elixir has been  a totally different experience. I did some reading. Liked the syntax, kept on reading, got hooked. Read a book and now I am writing a blog post praising the language. So I would say Elixir is much more approachable than Erlang with the same benefits.&lt;/p&gt;

&lt;p&gt;Elixir uses the same BEAM VM and offers the same advantages of Erlang - fault tolerance, scalability, easy concurrency while being a very productive language for the beginners (and of course for the more advanced users). Performance + Productivity = Win.&lt;/p&gt;

&lt;p&gt;The interoperability between Erlang and Elixir is also excellent. We can use Erlang standard library as well as third party packages from inside Elixir. So despite being a new language, Elixir can already leverage the underlying maturity of the VM and the years of hard work done in the Erlang eco system.&lt;/p&gt;

&lt;h3 id=&#34;why-i-am-so-excited-about-elixir&#34;&gt;Why I am so excited about Elixir?&lt;/h3&gt;

&lt;p&gt;In my day to day work, I am mostly a web developer. I have done my share of PHP and then moved on to Python. Today, I am a Python developer with most of my work being in Django. I absolutely love Django as the framework. But then I noticed Phoenix and Elixir. Some of the blog posts I came across heavily motivated me to explore both Elixir and Phoenix.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://hashrocket.com/blog/posts/websocket-shootout&#34;&gt;Elixir / Phoenix is awesome at handling websocket / real time communication&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://dockyard.com/blog/2016/08/09/phoenix-channels-vs-rails-action-cable&#34;&gt;Just look at the availability, scalability and response time - Phoenix Channels vs Rails Action Cable&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/mroth/phoenix-showdown&#34;&gt;Phoenix is very fast, very performant&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/doomspork/elixir-companies&#34;&gt;Many people are using it in production&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://medium.com/@Pinterest_Engineering/introducing-new-open-source-tools-for-the-elixir-community-2f7bb0bb7d8c#.on9d0vf5m&#34;&gt;Pinterest&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.techworld.com/apps/how-elixir-helped-bleacher-report-handle-8x-more-traffic-3653957/&#34;&gt;Bleacher Report handles 8x more traffic&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Not to mention I have played around a bit with a new Phoenix app. It was very easy to get started and everything made sense. I tried making some changes to see how it can fit my requirements. Surprisingly, achieving what I wanted to do didn&amp;rsquo;t take me much time although I was just a beginner. These things really attracted me. The community is very friendly and helpful. The tooling was superb (in fact much much better than what I am generally used to).&lt;/p&gt;

&lt;p&gt;With the growth of IoT, we will gradually feel the need of languages and platforms which can handle more and more concurrent connections. Elixir with Erlang and OTP in it&amp;rsquo;s back, will become one of the major players in the IoT arena.&lt;/p&gt;

&lt;p&gt;In short - I felt that Phoenix really delivers on it&amp;rsquo;s promise. It&amp;rsquo;s very performant while I am being productive. I am pretty hopeful that Elixir and Phoenix will be a very good choice for what I do at work.&lt;/p&gt;

&lt;h3 id=&#34;where-to-learn-about-elixir&#34;&gt;Where to learn about Elixir?&lt;/h3&gt;

&lt;p&gt;I really liked the wonderful Elixir School. The official documentation is also excellent. If you want to know what&amp;rsquo;s happening in the community, do keep an eye on Twitter, follow some key people. The Elixir subreddit is also a good place. And of course, don&amp;rsquo;t forget to join the Elixir Slack.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://elixirschool.com/&#34;&gt;Elixir School&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://elixir-slackin.herokuapp.com/&#34;&gt;Official Guides&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://elixir-lang.org/docs.html&#34;&gt;Docs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://elixir-slackin.herokuapp.com/&#34;&gt;Elixir Slack&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/h4cc/awesome-elixir&#34;&gt;Awesome Elixir&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://elixirfountain.com/&#34;&gt;Elixir Fountain&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://elixircasts.io/&#34;&gt;Elixir Casts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.reddit.com/r/elixir/&#34;&gt;Elixir Subreddit&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://elixirstatus.com/&#34;&gt;Elixir Status&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://elixirweekly.net/&#34;&gt;Elixir Weekly&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If you&amp;rsquo;re looking for book recommendation or other resources, checkout the &lt;a href=&#34;http://elixir-lang.org/learning.html&#34;&gt;Learning&lt;/a&gt; section on the official Elixir website.&lt;/p&gt;

&lt;h3 id=&#34;does-elixir-look-difficult-hard&#34;&gt;Does Elixir look difficult/hard?&lt;/h3&gt;

&lt;p&gt;Thought I must warn you - since Elixir is a functional programming language, it might take some time to get used to some parts of it, specially for those of us who have been playing in the object oriented world for too long. If you find parts of the language not so comfortable, skip that for the time being and explore other niceties. Some of the functional concepts might take a little time to comprehend but that&amp;rsquo;s alright. Give it some time and once you grasp the concepts, it will blow your mind away. You would love the power, flexibility and the expressiveness very soon.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Django Channels: Using Custom Channels</title>
      <link>http://masnun.rocks/2016/11/27/django-channels-using-custom-channels/</link>
      <pubDate>Sun, 27 Nov 2016 07:48:51 +0600</pubDate>
      
      <guid>http://masnun.rocks/2016/11/27/django-channels-using-custom-channels/</guid>
      <description>

&lt;p&gt;In my earlier blog post - &lt;a href=&#34;http://masnun.rocks/2016/09/25/introduction-to-django-channels/&#34;&gt;Introduction to Django Channels&lt;/a&gt;,
I mentioned that we can create our own channels for various purposes. In this blog post, we would discuss where custom channels
can be useful, what could be the challenges and of course we would see some code examples. But before we begin, please make sure
you are familiar with the concepts of Django Channels. I would recommend going through the above mentioned post and the official
docs to familiarize yourself with the basics.&lt;/p&gt;

&lt;h3 id=&#34;our-use-case&#34;&gt;Our Use Case&lt;/h3&gt;

&lt;p&gt;Channels is just a queue which has consumers (workers) listenning to it. With that concept in mind, we might be able to think of
many innovative use cases a queue could have. But in our example, we will keep the idea simple. We are going to use Channels as
a means of background task processing.&lt;/p&gt;

&lt;p&gt;We will create our own channels for different tasks. There will be consumers waiting for messages on these channels. When we want to
do something in the background, we would pass it on the appropriate channels &amp;amp; the workers will take care of the tasks. For example,
we want to create a thumbnail of an user uploaded photo? We pass it to the &lt;code&gt;thumbnails&lt;/code&gt; channel. We want to send a confirmation email,
we send it to the &lt;code&gt;welcome_email&lt;/code&gt; channel. Like that. If you are familiar with Celery or Python RQ, this would sound pretty
familiar to you.&lt;/p&gt;

&lt;p&gt;Now here&amp;rsquo;s my use case - in one of the projects I am working on, we&amp;rsquo;re building APIs for mobile applications. We use BrainTree for
payment integration. The mobile application sends a &lt;code&gt;nonce&lt;/code&gt; - it&amp;rsquo;s like a token that we can use to initiate the actual transaction.
The transaction has two steps - first we initiate it using the nonce and I get back a transaction id. Then I query whether the transaction
succeeded or failed. I felt it would be a good idea to process this in the background. We already have a websocket end point implemented
using Channels. So I thought it would be great to leverage the existing setup instead of introducing something new in the stack.&lt;/p&gt;

&lt;h3 id=&#34;challenges&#34;&gt;Challenges&lt;/h3&gt;

&lt;p&gt;It has so far worked pretty well. But we have to remember that Channels does not gurantee delivery of the messages and there is
no retrying if a message fails. So we wrote a custom management command that checks the orders for any records that have the nonce
set but no transaction id or there is transaction id but there is no final result stored. We then scheduled this command to run at
a certain interval and queue up the unfinished/incomplete orders again. In our case, it doesn&amp;rsquo;t hurt if the orders need some 5 to 10
minutes to process.&lt;/p&gt;

&lt;p&gt;But if we were working on a product where the message delivery was time critical for our business, we probably would have considered
Celery for the background processing part.&lt;/p&gt;

&lt;h3 id=&#34;let-s-see-the-codes&#34;&gt;Let&amp;rsquo;s see the codes!&lt;/h3&gt;

&lt;p&gt;First we needed to write a handler. The hadler would receive the messages on the subscribed channel and process them. Here&amp;rsquo;s the handler:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def braintree_process(message):
    order_data = message.content.get(&#39;order&#39;)
    order_id = message.content.get(&#39;order_id&#39;)
    order_instance = Order.objects.get(pk=order_id)

    if order_data:
        nonce = order_data.get(&amp;quot;braintree_nonce&amp;quot;)
        if nonce:
            # [snipped]

            TRANSACTION_SUCCESS_STATUSES = [
                braintree.Transaction.Status.Authorized,
                braintree.Transaction.Status.Authorizing,
                braintree.Transaction.Status.Settled,
                braintree.Transaction.Status.SettlementConfirmed,
                braintree.Transaction.Status.SettlementPending,
                braintree.Transaction.Status.Settling,
                braintree.Transaction.Status.SubmittedForSettlement
            ]

            result = braintree.Transaction.sale({
                &#39;amount&#39;: str(order_data.get(&#39;total&#39;)),
                &#39;payment_method_nonce&#39;: nonce,
                &#39;options&#39;: {
                    &amp;quot;submit_for_settlement&amp;quot;: True
                }
            })

            if result.is_success or result.transaction:
                transaction = braintree.Transaction.find(result.transaction.id)
                if transaction.status in TRANSACTION_SUCCESS_STATUSES:
                    # [snipped]
                else:
                    # [snipped]
            else:
                errors = []
                for x in result.errors.deep_errors:
                    errors.append(str(x.code))

                # [snipped]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then we needed to define a routing so the messages on a certain channel is passed on to this handler. So in our channel routing, we added
this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from channels.routing import route
from .channel_handlers import braintree_process

channel_routing = [
    route(&amp;quot;braintree_process&amp;quot;, braintree_process),
    # [snipped] ...
]

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We now have a routing set and a handler ready to accept messages. So we&amp;rsquo;re ready! All we need to do is to start passing the
data to this channel.&lt;/p&gt;

&lt;p&gt;When the API receives a &lt;code&gt;nonce&lt;/code&gt;, it just passes the order details to this channel:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;Channel(&amp;quot;braintree_process&amp;quot;).send({
    &amp;quot;order&amp;quot;: data,
    &amp;quot;order_id&amp;quot;: order.id
})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And then the workers start working. They accept the message and then starts processing the payment request.&lt;/p&gt;

&lt;p&gt;In our case, we already had the workers running (since they were serving our websocket requests). If you don&amp;rsquo;t have any workers running,
don&amp;rsquo;t forget to run them.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;python manage.py runworker
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you are wondering about how to deploy channels, I have you covered - &lt;a href=&#34;http://masnun.rocks/2016/11/02/deploying-django-channels-using-daphne/&#34;&gt;Deploying Django Channels using Daphne&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;prioritizing-scaling-channels&#34;&gt;Prioritizing / Scaling Channels&lt;/h3&gt;

&lt;p&gt;In our project, Django Channels do two things - handling websocket connections for realtime communication, process delayed jobs in
background. As you can probably guess, the realtime part is more important. In our current setup, the running workers handle both
types of requests as they come. But we want to dedicate more workers to the websocket and perhaps just one worker should keep processing
the payments.&lt;/p&gt;

&lt;p&gt;Luckily, we can limit our workers to certain channels using the &lt;code&gt;--only-channels&lt;/code&gt; flag. Or alternatively we can exclude certain
channels by using the &lt;code&gt;--exclude-channels&lt;/code&gt; flags.&lt;/p&gt;

&lt;h3 id=&#34;concluding-thoughts&#34;&gt;Concluding Thoughts&lt;/h3&gt;

&lt;p&gt;I personally find the design of channels very straightforward, simple and easy to reason about. When Channels get merged into Django,
it&amp;rsquo;s going to be quite useful, not just for implementing http/2 or websockets, but also as a way to process background tasks with ease
and without introducing third party libraries.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Exploring Asyncio - uvloop, sanic and motor</title>
      <link>http://masnun.rocks/2016/11/17/exploring-asyncio-uvloop-sanic-motor/</link>
      <pubDate>Thu, 17 Nov 2016 03:33:38 +0600</pubDate>
      
      <guid>http://masnun.rocks/2016/11/17/exploring-asyncio-uvloop-sanic-motor/</guid>
      <description>

&lt;p&gt;The &lt;code&gt;asyncio&lt;/code&gt; package was introduced in the standard library from Python 3.4. The package is still in provisional stage, that is
backward compatibility can be broken with future changes. However, the Python community is pretty excited about it and I know
personally that many people have started using it in production. So, I too decided to try it out. I built a rather simple
micro service using the excellent &lt;code&gt;sanic&lt;/code&gt; framework and &lt;code&gt;motor&lt;/code&gt; (for accessing mongodb). &lt;code&gt;uvloop&lt;/code&gt; is an alternative event loop
implementation written in Cython on top of libuv and can be used as a drop in replacement for asyncio&amp;rsquo;s event loop. Sanic uses
&lt;code&gt;uvloop&lt;/code&gt; behind the scene to go fast.&lt;/p&gt;

&lt;p&gt;In this blog post, I would quickly introduce the technologies involved and then walk through some sample code with relevant explanations.&lt;/p&gt;

&lt;h3 id=&#34;what-is-asyncio-why-should-i-care&#34;&gt;What is Asyncio? Why Should I Care?&lt;/h3&gt;

&lt;p&gt;In one of my earlier blog post - &lt;a href=&#34;http://masnun.rocks/2016/10/06/async-python-the-different-forms-of-concurrency/&#34;&gt;Async Python: The Different Forms of Concurrency&lt;/a&gt;,
I have tried to elaborate on the different ways to achieve concurrency in the Python land. In the last part of the post, I have tried
to explain what asyncio brings new to the table.&lt;/p&gt;

&lt;p&gt;Asyncio allows us to write asynchronous, concurrent programs running on a single thread, using an event loop to schedule tasks and
multiplexing I/O over sockets (and other resources). The one line explanation might be a little complex to comprehend at a glance. So
I will break it down. In asyncio, everything runs on a single thread. We use coroutines which can be treated as small units of task
that we can pause and resume. Then there is I/O multiplexing - when our tasks are busy waiting for I/O, an event loop pauses them
and allows other tasks to run. When the paused tasks finish I/O, the event loop resumes them. This way even a single thread can
handle / serve a large number of connections / clients by effectively juggling between &amp;ldquo;active&amp;rdquo; tasks and tasks that are waiting
for some sort of I/O.&lt;/p&gt;

&lt;p&gt;In general synchronous style, for example, when we&amp;rsquo;re using thread based concurrency, each client will occupy a thread and when
we have a large number of connections, we will soon run out of threads. Though not all of those threads were active at a given time,
some might have been simply waiting for I/O, doing nothing. Asyncio helps us solve this problem and provides an efficient solution
to the concurrency problem.&lt;/p&gt;

&lt;p&gt;While Twisted, Tornado and many other solutions have existed in the past, NodeJS brought huge attention to this kind of solution.
And with Asyncio being in the standard library, I believe it will become the standard way of doing async I/O in the Python world over
time.&lt;/p&gt;

&lt;h3 id=&#34;what-about-uvloop&#34;&gt;What about uvloop?&lt;/h3&gt;

&lt;p&gt;We talked about event loop above. It schedules the tasks and deals with various events. It also manages the I/O multiplexing using
the various options offered by the operating system. In simple words - the event loop is very critical and the central part of the
whole asyncio operations. The &lt;code&gt;asyncio&lt;/code&gt; package ships with an event loop by default. But we can also swap it for our custom
implementations if we need/prefer. &lt;code&gt;uvloop&lt;/code&gt; is one such event loop that is very very fast. The key to it&amp;rsquo;s success could be partially
attributed to Cython. Cython allows us to write codes in Python like syntax while the codes perform like C. &lt;code&gt;uvloop&lt;/code&gt; was written in
Cython and it uses the famous &lt;code&gt;libuv&lt;/code&gt; library (also used by NodeJS).&lt;/p&gt;

&lt;p&gt;If you are wondering if &lt;code&gt;uvloop&lt;/code&gt;&amp;rsquo;s performances are good enough reason to swap out the default event loop, you may want to read this
aricle here - &lt;a href=&#34;https://magic.io/blog/uvloop-blazing-fast-python-networking/&#34;&gt;uvloop: Blazing fast Python networking&lt;/a&gt; or you can just
look at this following chart taken from that blog post:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://i.imgur.com/0iMUePy.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Yes, it can go faster than NodeJS and catch up to Golang. Convinced yet? Let&amp;rsquo;s talk about Sanic!&lt;/p&gt;

&lt;h3 id=&#34;sanic-gotta-go-fast&#34;&gt;Sanic - Gotta go fast!&lt;/h3&gt;

&lt;p&gt;Sanic was inspired by the above article I talked about. They used &lt;code&gt;uvloop&lt;/code&gt; and &lt;code&gt;httptools&lt;/code&gt; too (referenced in the article). The
framework provides a nice, Flask like syntax along with the &lt;code&gt;async / await&lt;/code&gt; syntax from Python 3.5.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Please Note:&lt;/strong&gt; &lt;code&gt;uvloop&lt;/code&gt; still doesn&amp;rsquo;t work on Windows properly. Sanic uses the default asyncio event loop if uvloop
is not available. But this probably doesn&amp;rsquo;t matter because in most cases we deploy to linux machines anyway. Just in case you
want to try out the performance gains on Windows, I recommend you use a VM to test it inside a Linux machine.&lt;/p&gt;

&lt;h3 id=&#34;motor&#34;&gt;Motor&lt;/h3&gt;

&lt;p&gt;Motor started off as an async mongodb driver for Tornado. Motor = &lt;strong&gt;Mo&lt;/strong&gt;ngodb + &lt;strong&gt;Tor&lt;/strong&gt;nado. But Motor
now has pretty nice support for asyncio. And of course we can use the &lt;code&gt;async / await&lt;/code&gt; syntax too.&lt;/p&gt;

&lt;p&gt;I guess we have had brief introductions to the technologies we are going to use. So let&amp;rsquo;s get started with the actual work.&lt;/p&gt;

&lt;h3 id=&#34;setting-up&#34;&gt;Setting Up&lt;/h3&gt;

&lt;p&gt;We need to install &lt;code&gt;sanic&lt;/code&gt; and &lt;code&gt;motor&lt;/code&gt; using &lt;code&gt;pip&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pip install sanic
pip install motor
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Sanic should also install it&amp;rsquo;s dependencies including &lt;code&gt;uvloop&lt;/code&gt; and &lt;code&gt;ujson&lt;/code&gt; along with others.&lt;/p&gt;

&lt;h3 id=&#34;set-uvloop-as-the-event-loop&#34;&gt;Set &lt;code&gt;uvloop&lt;/code&gt; as the event loop&lt;/h3&gt;

&lt;p&gt;We will swap out the default event loop and use &lt;code&gt;uvloop&lt;/code&gt; instead.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import asyncio
import uvloop

asyncio.set_event_loop_policy(uvloop.EventLoopPolicy())
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Simple as that. We import asyncio and uvloop. We set the event loop policy to uvloop&amp;rsquo;s event loop policy and we&amp;rsquo;re done. Now
asyncio will use uvloop as the default event loop.&lt;/p&gt;

&lt;h3 id=&#34;connecting-to-mongodb&#34;&gt;Connecting to Mongodb&lt;/h3&gt;

&lt;p&gt;We will be using &lt;code&gt;motor&lt;/code&gt; to connect to our mongodb. Just like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from motor.motor_asyncio import AsyncIOMotorClient

mongo_connection = AsyncIOMotorClient(&amp;quot;&amp;lt;mongodb connection string&amp;gt;&amp;quot;)

contacts = mongo_connection.mydatabase.contacts
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We import the &lt;code&gt;AsyncIOMotorClient&lt;/code&gt; and pass our mongodb connection string to it. We also point to our target collection
using a name / variable so that we can easily (and directly) use that collection later. Here &lt;code&gt;mydatabase&lt;/code&gt; is the db name
and &lt;code&gt;contacts&lt;/code&gt; is the collection name.&lt;/p&gt;

&lt;h3 id=&#34;request-handlers&#34;&gt;Request Handlers&lt;/h3&gt;

&lt;p&gt;Now we will dive right in and write our request handlers. For our demo application, I will create two routes. One for listing
the contacts and one for creating new ones. But first we must instantiate sanic.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from sanic import Sanic
from sanic.response import json

app = Sanic(__name__)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Flask-like, remember? Now that we have the &lt;code&gt;app&lt;/code&gt; instance, let&amp;rsquo;s add routes to it.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;@app.route(&amp;quot;/&amp;quot;)
async def list(request):
    data = await contacts.find().to_list(20)
    for x in data:
        x[&#39;id&#39;] = str(x[&#39;_id&#39;])
        del x[&#39;_id&#39;]

    return json(data)


@app.route(&amp;quot;/new&amp;quot;)
async def new(request):
    contact = request.json
    insert = await contacts.insert_one(contact)
    return json({&amp;quot;inserted_id&amp;quot;: str(insert.inserted_id)})

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The routes are simple and for the sake of brevity, I haven&amp;rsquo;t written any error handling codes. The &lt;code&gt;list&lt;/code&gt; function is &lt;code&gt;async&lt;/code&gt;.
Inside it we &lt;code&gt;await&lt;/code&gt; our contacts to arrive from the database, as a list of 20 entries. In a sync style, we would use the &lt;code&gt;find&lt;/code&gt;
method directly but now we &lt;code&gt;await&lt;/code&gt; it.&lt;/p&gt;

&lt;p&gt;After we have the results, we quickly iterate over the documents and add &lt;code&gt;id&lt;/code&gt; key and remove the &lt;code&gt;_id&lt;/code&gt; key. The &lt;code&gt;_id&lt;/code&gt; key is an
instance of &lt;code&gt;ObjectId&lt;/code&gt; which would need us to use the &lt;code&gt;bson&lt;/code&gt; package for serialization. To avoid complexity here, we just convert
the id to string and then delete the ObjectId instance. The rest of the document is usual string based key-value pairs (&lt;code&gt;dict&lt;/code&gt;).
So it should serialize fine.&lt;/p&gt;

&lt;p&gt;In the &lt;code&gt;new&lt;/code&gt; function, we grab the incoming json payload and pass it to the &lt;code&gt;insert_one&lt;/code&gt; method directly. &lt;code&gt;request.json&lt;/code&gt; would
contain the &lt;code&gt;dict&lt;/code&gt; representation of the json request. Check out &lt;a href=&#34;https://github.com/channelcat/sanic/blob/master/docs/request_data.md&#34;&gt;this page&lt;/a&gt;
for other request data available to you. Here, we again &lt;code&gt;await&lt;/code&gt; the &lt;code&gt;insert_one&lt;/code&gt; call. When the response is available, we
take the &lt;code&gt;inserted_id&lt;/code&gt; and send a response back.&lt;/p&gt;

&lt;h3 id=&#34;running-the-app&#34;&gt;Running the App&lt;/h3&gt;

&lt;p&gt;Let&amp;rsquo;s see the code first:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;loop = asyncio.get_event_loop()

app.run(host=&amp;quot;0.0.0.0&amp;quot;, port=8000, workers=3, debug=True, loop=loop)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here we get the default event loop and pass it to &lt;code&gt;app.run&lt;/code&gt; along with other obvious options. With the &lt;code&gt;workers&lt;/code&gt; argument,
we can set how many workers we want to use. This allows us to spin up multiple workers and take advantages of multiple cpu
cores. On a single core machine, we can just set it to 1 or totally skip that one.&lt;/p&gt;

&lt;p&gt;The &lt;code&gt;loop&lt;/code&gt; is optional as well. If we do not pass the loop, sanic will create a new one and set it as the default loop. But in
our case, we have connected to mongodb using motor before the &lt;code&gt;app.run&lt;/code&gt; function could actually run. Motor now already uses the
default event loop. If we don&amp;rsquo;t pass that same loop to sanic, sanic will initialize a new event loop. Our database access and
sanic server will be on two different event loops and we won&amp;rsquo;t be able to make database calls. That is why we use the &lt;code&gt;get_event_loop&lt;/code&gt;
function to retrieve the current default event loop and pass it to sanic. This is also why we set &lt;code&gt;uvloop&lt;/code&gt; as the default event
loop on top of the file. Otherwise we would end up with the default loop (that comes with asyncio) and sanic would also have to
use that. Initializing &lt;code&gt;uvloop&lt;/code&gt; at the beginning makes sure everyone uses it.&lt;/p&gt;

&lt;h3 id=&#34;final-code&#34;&gt;Final Code&lt;/h3&gt;

&lt;p&gt;So here&amp;rsquo;s the final code. We probably should clean up the imports and bring them up on top. But to relate to the different steps,
I kept them as is. Also as mentioned earlier, the code has no error handling. We should write proper error handling code in all
serious projects.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import asyncio
import uvloop

asyncio.set_event_loop_policy(uvloop.EventLoopPolicy())



from motor.motor_asyncio import AsyncIOMotorClient

mongo_connection = AsyncIOMotorClient(&amp;quot;&amp;lt;connection string&amp;gt;&amp;quot;)

contacts = mongo_connection.mydatabase.contacts


from sanic import Sanic
from sanic.response import json

app = Sanic(__name__)


@app.route(&amp;quot;/&amp;quot;)
async def list(request):
    data = await contacts.find().to_list(20)
    for x in data:
        x[&#39;id&#39;] = str(x[&#39;_id&#39;])
        del x[&#39;_id&#39;]

    return json(data)


@app.route(&amp;quot;/new&amp;quot;)
async def new(request):
    contact = request.json
    insert = await contacts.insert_one(contact)
    return json({&amp;quot;inserted_id&amp;quot;: str(insert.inserted_id)})


loop = asyncio.get_event_loop()

app.run(host=&amp;quot;0.0.0.0&amp;quot;, port=8000, workers=3, debug=True, loop=loop)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now let&amp;rsquo;s try it out?&lt;/p&gt;

&lt;h3 id=&#34;trying-out&#34;&gt;Trying Out&lt;/h3&gt;

&lt;p&gt;I have saved the above code as &lt;code&gt;main.py&lt;/code&gt;. So let&amp;rsquo;s run it.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python main.py
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we can use &lt;code&gt;curl&lt;/code&gt; to try it out. Let&amp;rsquo;s first add a contact:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;curl -X POST -H &amp;quot;Content-Type: application/json&amp;quot; -d &#39;{&amp;quot;name&amp;quot;: &amp;quot;masnun&amp;quot;}&#39; &amp;quot;http://localhost:8000/new&amp;quot;

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We should see something like:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{&amp;quot;inserted_id&amp;quot;:&amp;quot;582ceb772c608731477f5384&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s verify by checking &lt;code&gt;/&lt;/code&gt; -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;curl -X GET &amp;quot;http://localhost:8000/&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If everything goes right, we should see something like:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[{&amp;quot;id&amp;quot;:&amp;quot;582ceb772c608731477f5384&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;masnun&amp;quot;}]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I hope it works for you too! :-)&lt;/p&gt;

&lt;p&gt;If you have any feedback or suggestions, please feel free to share it in the comments section. I would love to disqus :-)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Golang: Building a Telegram bot for Aggregating Content</title>
      <link>http://masnun.rocks/2016/11/05/golang-building-a-telegram-bot-for-aggregating-content/</link>
      <pubDate>Sat, 05 Nov 2016 22:36:10 +0600</pubDate>
      
      <guid>http://masnun.rocks/2016/11/05/golang-building-a-telegram-bot-for-aggregating-content/</guid>
      <description>

&lt;p&gt;I was looking for some fun excercises to learn Go. At the same time, I also started to feel the need of an
automated program or simply put, a bot who can find contents from different sources and push them to a
messaging service where I can read them all in one place. I briefly considered Facebook Messenger but settled
for Telegram as the messaging service of choice. Telegram has apps for both phones and macs/pcs. They also
have an excellent set of well documented APIs.&lt;/p&gt;

&lt;p&gt;To begin with, I have already implemented pushing latest contents from my reddit front page to Telegram. The
work in progress code can be found here: &lt;a href=&#34;https://github.com/masnun/telegram-bot&#34;&gt;https://github.com/masnun/telegram-bot&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;the-idea&#34;&gt;The Idea&lt;/h3&gt;

&lt;p&gt;The program has these major parts now:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;SQLite Database (Used with &lt;code&gt;Gorm&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;Telegram API&lt;/li&gt;
&lt;li&gt;Reddit API&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The program will be run periodically via cron job. On each execution, it will run a set of &lt;code&gt;tasks&lt;/code&gt; - one
task would be to fetch reddit content, another task would parse my rss feed, some other task would track
certain keywords on twitter - you get the idea! The main program is composed of these tasks and
they would be run one after one (or may be on separate goroutines in the future?). For now I have only one
task that fetches posts from my reddit front page.&lt;/p&gt;

&lt;p&gt;Since the app will have at best one user, SQLite should be fine for the use case. I chose &lt;code&gt;Gorm&lt;/code&gt; as the ORM.
In this blog post, I will quickly go through how these different parts work.&lt;/p&gt;

&lt;h3 id=&#34;using-sqlite-with-gorm&#34;&gt;Using SQLite with Gorm&lt;/h3&gt;

&lt;p&gt;If you have worked with Go for a while, you probably already know about &lt;code&gt;Gorm&lt;/code&gt; - it&amp;rsquo;s a really nice ORM for Go.
Installing &lt;code&gt;Gorm&lt;/code&gt; is simply -&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;go get -u github.com/jinzhu/gorm
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Once we have Gorm installed, let&amp;rsquo;s first define our first model. To keep track of which posts the bot has already
pushed to Telegram, we will store the pushed posts in the database. For that, we will need one simple table where
we can store the permalink of a post.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s the &lt;code&gt;RedditPost&lt;/code&gt; struct from &lt;code&gt;dao/entities.go&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-golang&#34;&gt;package dao

import (
	&amp;quot;github.com/jinzhu/gorm&amp;quot;
)

// RedditPost - Struct for storing Reddit Posts
// Used by `gorm`
type RedditPost struct {
	gorm.Model
	PermaLink string
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As you can see the &lt;code&gt;PermaLink&lt;/code&gt; field would contain the permalink for each post. Now we write a &lt;code&gt;Init&lt;/code&gt; function
which will setup the connection, run any necessary (auto) migrations and return a &lt;code&gt;DB&lt;/code&gt; handler so we can start
making queries. Here&amp;rsquo;s the code from &lt;code&gt;dao/gorm.go&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package dao

import (
	&amp;quot;github.com/jinzhu/gorm&amp;quot;
	_ &amp;quot;github.com/jinzhu/gorm/dialects/sqlite&amp;quot; // for db
)

// Init - Initialize database and return a  handler
func Init() *gorm.DB {
	db, err := gorm.Open(&amp;quot;sqlite3&amp;quot;, &amp;quot;telegram.db&amp;quot;)
	if err != nil {
		panic(&amp;quot;failed to connect database&amp;quot;)
	}

	db.AutoMigrate(&amp;amp;RedditPost{})

	return db
}

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here, we are using the &lt;code&gt;AutoMigrate&lt;/code&gt; function to automatically apply any changes to the &lt;code&gt;RedditPost&lt;/code&gt; model. On the
first run, the table will be created if it does not exist.&lt;/p&gt;

&lt;p&gt;Finally, we need to write the functions which will actually make database operations. For our current task,
we just need two functions:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;One to check if the post exists already (pushed to telegram before)&lt;/li&gt;
&lt;li&gt;Store a new post&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I have these functionality defined in &lt;code&gt;dao/utils.go&lt;/code&gt; -&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;package dao

import (
	&amp;quot;fmt&amp;quot;
)

// Exists - check if an item exists in db
func Exists(PermaLink string) bool {
	db := Init()
	defer db.Close()
	var post RedditPost
	result := db.First(&amp;amp;post, &amp;quot;perma_link = ?&amp;quot;, PermaLink)
	if result.Error != nil {
		errorMsg := result.Error.Error()

		if errorMsg == &amp;quot;record not found&amp;quot; {
			return false
		}

		fmt.Println(errorMsg)

	}

	return true

}

// Create post
func Create(PermaLink string) {
	db := Init()
	defer db.Close()
	var post = RedditPost{PermaLink: PermaLink}
	result := db.Create(&amp;amp;post)
	if result.Error != nil {
		errorMsg := result.Error.Error()
		fmt.Println(errorMsg)

	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Each time, we first get the connection to the database by calling &lt;code&gt;Init&lt;/code&gt; and then make &lt;code&gt;defer&lt;/code&gt;red call to &lt;code&gt;Close()&lt;/code&gt;
so the database connection is cleaned up when the function completes. Then we use the db connection to make queries.&lt;/p&gt;

&lt;p&gt;In the &lt;code&gt;Exists&lt;/code&gt; function, I probably should have just used &lt;code&gt;Count&lt;/code&gt; functionality instead of the complex &lt;code&gt;First&lt;/code&gt;
call and error checking. But I was learning and wanted to try something unconventional. One thing to note here is
that the column name is &lt;code&gt;perma_link&lt;/code&gt; instead of the struct field being &lt;code&gt;PermaLink&lt;/code&gt;. This is Gorm convention to make
the column snake case version of the struct field. We can however define our column names quite easily.
For more details, please check their docs - &lt;a href=&#34;http://jinzhu.me/gorm/models.html&#34;&gt;http://jinzhu.me/gorm/models.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In the &lt;code&gt;Create&lt;/code&gt; function we use &lt;code&gt;db.Create&lt;/code&gt; to create the entry in database. That&amp;rsquo;s all!&lt;/p&gt;

&lt;h3 id=&#34;reading-our-reddit-frontpage&#34;&gt;Reading our Reddit Frontpage&lt;/h3&gt;

&lt;p&gt;I am using &lt;code&gt;github.com/jzelinskie/geddit&lt;/code&gt; to login to Reddit and grab the posts on the front page. Here&amp;rsquo;s the
code from &lt;code&gt;tasks/reddit.go&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package tasks

import (
	&amp;quot;fmt&amp;quot;
	&amp;quot;os&amp;quot;

	&amp;quot;github.com/jzelinskie/geddit&amp;quot;
	&amp;quot;github.com/masnun/telegram-bot/dao&amp;quot;
	&amp;quot;github.com/masnun/telegram-bot/utils&amp;quot;
)

func PushReddit() {
	session, err := geddit.NewLoginSession(
		os.Getenv(&amp;quot;REDDIT_USERNAME&amp;quot;),
		os.Getenv(&amp;quot;REDDIT_PASSWORD&amp;quot;),
		&amp;quot;gedditAgent v1&amp;quot;,
	)

	if err != nil {
		fmt.Println(&amp;quot;Reddit Login Error: &amp;quot;, err)
		return
	}

	subOpts := geddit.ListingOptions{
		Limit: 15,
	}

	submissions, _ := session.Frontpage(geddit.DefaultPopularity, subOpts)

	for _, s := range submissions {
		if exists := dao.Exists(s.Permalink); !exists {
			fmt.Printf(&amp;quot;Title: %s\nAuthor: %s\n\n&amp;quot;, s.Title, s.Permalink)
			dao.Create(s.Permalink)
			utils.SendTelegramMessage(fmt.Sprintf(&amp;quot;%s : https://www.reddit.com/%s&amp;quot;, s.Title, s.Permalink))
		} else {
			fmt.Println(&amp;quot;Exists: &amp;quot;, s.Permalink)
		}

	}

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here we first login to Reddit. The credentials are stored using environment variables. I use a file named
&lt;code&gt;configure.sh&lt;/code&gt; to &lt;code&gt;export&lt;/code&gt; the variables. You can copy the existing
&lt;a href=&#34;https://github.com/masnun/telegram-bot/blob/master/configure.sh.sample&#34;&gt;&lt;code&gt;configure.sh.sample&lt;/code&gt;&lt;/a&gt;
file and store it as &lt;code&gt;configure.sh&lt;/code&gt;. Fill up the credentials and then do this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;. ./configure.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This should set the environment variables. Please make sure to complete this process before you run the program.&lt;/p&gt;

&lt;p&gt;After connecting to reddit, we fetch 15 posts, &lt;code&gt;range&lt;/code&gt; through them and if a new post is found, we post the title
and url to Telegram.&lt;/p&gt;

&lt;h3 id=&#34;posting-to-telegram&#34;&gt;Posting to Telegram&lt;/h3&gt;

&lt;p&gt;First create a bot by contacting the infamous &lt;code&gt;BotFather&lt;/code&gt; on Telegram. Once you have the Token, we&amp;rsquo;ll need one
more thing - your chat ID so the bot can directly send you the message.&lt;/p&gt;

&lt;p&gt;First, &lt;code&gt;go get&lt;/code&gt; the project we shall use to connect to Telegram:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;go get github.com/go-telegram-bot-api/telegram-bot-api
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then go ahead and run the sample codes available on:
&lt;a href=&#34;https://github.com/go-telegram-bot-api/telegram-bot-api&#34;&gt;https://github.com/go-telegram-bot-api/telegram-bot-api&lt;/a&gt; and you can get the chat id from &lt;code&gt;update.Message.Chat.ID&lt;/code&gt;.
After extracting the chat ID, store it in the &lt;code&gt;configure.sh&lt;/code&gt; file.&lt;/p&gt;

&lt;p&gt;Now, we write a very simple function to post to our user. Here&amp;rsquo;s the code from &lt;code&gt;utils/telegram.go&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;
package utils

import (
	&amp;quot;os&amp;quot;
	&amp;quot;strconv&amp;quot;

	&amp;quot;fmt&amp;quot;

	&amp;quot;gopkg.in/telegram-bot-api.v4&amp;quot;
)

func SendTelegramMessage(message string) {

	bot, err := tgbotapi.NewBotAPI(os.Getenv(&amp;quot;TELEGRAM_KEY&amp;quot;))
	if err != nil {
		fmt.Println(err.Error())
	}

	if bot.Self.UserName == &amp;quot;&amp;quot; {
		fmt.Println(&amp;quot;Error connecting to Telegram!&amp;quot;)
		return
	}

	chatID, _ := strconv.ParseInt(os.Getenv(&amp;quot;TELEGRAM_OWNER_CHATID&amp;quot;), 10, 64)
	msg := tgbotapi.NewMessage(chatID, message)
	bot.Send(msg)

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We connect to telegram using the token we received from BotFather. Then to make sure that the auth was successful,
we check the username of the bot. Then we construct a new message using the chat id and the message we get as
argument. We send it. The code is pretty simple and straightforward.&lt;/p&gt;

&lt;h3 id=&#34;building-and-running&#34;&gt;Building and Running&lt;/h3&gt;

&lt;p&gt;First make sure you have the correct details in &lt;code&gt;configure.sh&lt;/code&gt; file and you have the environment variables set. If
not, set them:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;. ./configure.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we build and run:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;
go build -o bot
./bot
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If everything goes alright, you should see the latest reddit front page submissions are posted to your telegram :)&lt;/p&gt;

&lt;h5 id=&#34;slow-build&#34;&gt;Slow Build?&lt;/h5&gt;

&lt;p&gt;If you&amp;rsquo;re using vendoring like me and you notice the build is taking slow, it&amp;rsquo;s probably because of the sqlite
driver. These should fix that:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cd ./vendor/github.com/mattn/go-sqlite3/
go install
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;what-s-next&#34;&gt;What&amp;rsquo;s next?&lt;/h3&gt;

&lt;p&gt;I am yet to integrate other sources. Hacker News, RSS feeds, tweets and other stuff would be nice to add.
Later it would be a good idea to implement some sort of intelligent filtering / sorting of the contents
based on my interests/reading habits.&lt;/p&gt;

&lt;p&gt;I really hope to learn some Golang by building the stuff. If you notice some bad practices or scopes of
improvement, please feel free to suggest those in the comment section.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Deploying Django Channels using Daphne</title>
      <link>http://masnun.rocks/2016/11/02/deploying-django-channels-using-daphne/</link>
      <pubDate>Wed, 02 Nov 2016 07:07:09 +0600</pubDate>
      
      <guid>http://masnun.rocks/2016/11/02/deploying-django-channels-using-daphne/</guid>
      <description>

&lt;p&gt;In one of my &lt;a href=&#34;http://masnun.rocks/2016/09/25/introduction-to-django-channels/&#34;&gt;earlier post&lt;/a&gt;, we
have seen an overview of how Django Channels work and how it helps us build cool stuff. However, in that post,
we covered deployment briefly. So here in this post, we shall go over deployment again, with a little more details
and of course code samples.&lt;/p&gt;

&lt;h3 id=&#34;what-do-we-need&#34;&gt;What do we need?&lt;/h3&gt;

&lt;p&gt;For running Django Channels, we would use the following setup:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;nginx as the proxy&lt;/li&gt;
&lt;li&gt;daphne as the interface server&lt;/li&gt;
&lt;li&gt;redis as the backend&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Let&amp;rsquo;s get started.&lt;/p&gt;

&lt;h3 id=&#34;setup-redis-and-configure-app&#34;&gt;Setup Redis and Configure App&lt;/h3&gt;

&lt;p&gt;We need to setup redis if it&amp;rsquo;s not installed already. Here&amp;rsquo;s how to do it on Ubuntu:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo apt-get install redis-server
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If we want to use the redis backend, we also need to setup &lt;code&gt;asgi-redis&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pip install asgi_redis
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In your &lt;code&gt;settings.py&lt;/code&gt; file, make sure you used redis as the backend and input the host properly.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s a demo:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;CHANNEL_LAYERS = {
    &amp;quot;default&amp;quot;: {
        &amp;quot;BACKEND&amp;quot;: &amp;quot;asgi_redis.RedisChannelLayer&amp;quot;,
        &amp;quot;CONFIG&amp;quot;: {
            &amp;quot;hosts&amp;quot;: [(&amp;quot;localhost&amp;quot;, 6379)],
        },
        &amp;quot;ROUTING&amp;quot;: &amp;quot;realtime.routing.channel_routing&amp;quot;,
    },
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;starting-daphne&#34;&gt;Starting Daphne&lt;/h3&gt;

&lt;p&gt;If you have installed &lt;code&gt;channels&lt;/code&gt; from pip, you should have the &lt;code&gt;daphne&lt;/code&gt; command available already. In the very
unlikely case you don&amp;rsquo;t have it installed, here&amp;rsquo;s the command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pip install daphne
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To run daphne, we use the following command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;daphne -b 0.0.0.0 -p 8001 &amp;lt;app&amp;gt;.asgi:channel_layer
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Daphne will bind to &lt;code&gt;0.0.0.0&lt;/code&gt; and use &lt;code&gt;8001&lt;/code&gt; as the port.&lt;/p&gt;

&lt;p&gt;Here &lt;code&gt;&amp;lt;app&amp;gt;&lt;/code&gt; is our app name / the module that contains the &lt;code&gt;asgi.py&lt;/code&gt; file. Please refer to the previous blog post
to know what we put in the &lt;code&gt;asgi.py&lt;/code&gt; file.&lt;/p&gt;

&lt;p&gt;We now need to make sure &lt;code&gt;daphne&lt;/code&gt; is automatically started at system launch and restarted when it crashes. In this
example, I would stick to my old upstart script. But you would probably want to explore excellent projects like
&lt;code&gt;circus&lt;/code&gt; or &lt;code&gt;supervisor&lt;/code&gt; or at least &lt;code&gt;systemd&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s the upstart script I use:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;start on runlevel [2345]
stop on runlevel [016]

respawn

script
    cd /home/ubuntu/&amp;lt;app home&amp;gt;
    export DJANGO_SETTINGS_MODULE=&amp;quot;&amp;lt;app&amp;gt;.production_settings&amp;quot;
    exec daphne -b 0.0.0.0 -p 8001 &amp;lt;app&amp;gt;.asgi:channel_layer
end script

&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;running-workers&#34;&gt;Running Workers&lt;/h3&gt;

&lt;p&gt;We need at least one running worker before daphne can start processing requests. To run a worker, we use the
following command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;python manage.py runworker
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;runworker&lt;/code&gt; command spawns one worker with one thread. We should have more than one ideally. It is recommended
to have &lt;code&gt;n&lt;/code&gt; number of workers where &lt;code&gt;n&lt;/code&gt; is the number of available cpu cores.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s a simple upstart script to keep the worker running:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;start on runlevel [2345]
stop on runlevel [016]

respawn

script
    cd /home/ubuntu/&amp;lt;app home&amp;gt;
    export DJANGO_SETTINGS_MODULE=&amp;quot;&amp;lt;app&amp;gt;.production_settings&amp;quot;
    exec python3 manage.py runworker
end script
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It would be much easier to launch multiple workers if you use supervisord or circus.&lt;/p&gt;

&lt;h3 id=&#34;nginx-conf&#34;&gt;Nginx Conf&lt;/h3&gt;

&lt;p&gt;Finally here&amp;rsquo;s the nginx conf I use. Please note I handle all incoming requests with daphne which is probably
not ideal. You can keep using &lt;code&gt;uwsgi&lt;/code&gt; for your existing, non real time parts and only handle the real time part
with daphne. Since setting up wsgi is popular knowledge, I will just focus on what we need for daphne.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;server {
    listen 80;
    client_max_body_size 20M;

    location /static {
       	alias /home/ubuntu/&amp;lt;app home&amp;gt;/static;

    }

    location /media {
        alias /home/ubuntu/&amp;lt;app home&amp;gt;/media;

    }

    location / {


       	    proxy_pass http://0.0.0.0:8001;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection &amp;quot;upgrade&amp;quot;;

            proxy_redirect     off;
            proxy_set_header   Host $host;
            proxy_set_header   X-Real-IP $remote_addr;
            proxy_set_header   X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header   X-Forwarded-Host $server_name;

        }

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We have our daphne server running on port &lt;code&gt;8001&lt;/code&gt; so we set a proxy to that url. Now if daphne and worker are
running, we should be able to see our webpage when we visit the url.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Distributed Task Processing in Go</title>
      <link>http://masnun.rocks/2016/11/01/distributed-task-processing-in-golang/</link>
      <pubDate>Tue, 01 Nov 2016 22:31:09 +0600</pubDate>
      
      <guid>http://masnun.rocks/2016/11/01/distributed-task-processing-in-golang/</guid>
      <description>

&lt;p&gt;I started playing with Go almost a year ago but never really managed to dive deeper or do anything serious with
it. Recently picked it up again, reading and trying out bits of code on and off. Also started this new blog with
Hugo (which is written in Go as well). As a language, Go is simple yet performant. I am definitely going to
build a few micro services with Go soon.&lt;/p&gt;

&lt;p&gt;Having said that, I was wondering what I could use to build a distributed task processing system. What I wanted is
something similar to Celery in the Python land. Luckily, I found
&lt;a href=&#34;https://github.com/RichardKnop/machinery&#34; target=&#34;_blank&#34;&gt;machinery&lt;/a&gt; which is inspired by Celery and
has nice APIs to achieve similar results. In this blog post, I am going to demonstrate a simple example.&lt;/p&gt;

&lt;p&gt;The source code is available here: &lt;a href=&#34;https://github.com/masnun/golang-distributed-task-processing&#34; target=&#34;_blank&#34;&gt;masnun/golang-distributed-task-processing&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;getting-started&#34;&gt;Getting started&lt;/h3&gt;

&lt;p&gt;Here&amp;rsquo;s what we&amp;rsquo;re going to do:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;There will be at least one worker which will be running and waiting for tasks&lt;/li&gt;
&lt;li&gt;We will be sending task request from another process&lt;/li&gt;
&lt;li&gt;We will be using Redis as the message queue&lt;/li&gt;
&lt;li&gt;Ideally the setup would be distributed, that is the worker might run in a separate machine. But for this
example, I will run both the worker and the task sender on the same machine.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;get-the-dependencies&#34;&gt;Get the dependencies&lt;/h3&gt;

&lt;p&gt;We need to install &lt;code&gt;machinery&lt;/code&gt; first. I am using Glide for dependency management in this project. But
that is not compulsory. &lt;code&gt;go get&lt;/code&gt; should work fine. So first, let&amp;rsquo;s install machinery -&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;go get github.com/RichardKnop/machinery/v1
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;writing-task-and-worker&#34;&gt;Writing Task and worker&lt;/h3&gt;

&lt;p&gt;Workers are processes which keep running, waiting for task requests. Tasks are functions which can be
requested and then the workers execute those functions and return the results.&lt;/p&gt;

&lt;p&gt;Say we have a task named &lt;code&gt;Say&lt;/code&gt;. From some other processes, we would request that the &lt;code&gt;Say&lt;/code&gt; task be executed.
The worker that will receive the request will find which function is registered as the &lt;code&gt;Say&lt;/code&gt; task and then
call the function with the received arguments. The result from the function is then stored and can be retrieved
by the other parties.&lt;/p&gt;

&lt;p&gt;So we first need to write a simple task. We will be writing a function named &lt;code&gt;Say&lt;/code&gt; which will accept a name and
say hello. So let&amp;rsquo;s create a directory named &lt;code&gt;worker&lt;/code&gt; and inside create a file named &lt;code&gt;hello.go&lt;/code&gt;. In the file,
let&amp;rsquo;s define this function:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main

// Say &amp;quot;Hello World&amp;quot;
func Say(name string) (string, error) {
	return &amp;quot;Hello &amp;quot; + name + &amp;quot;!&amp;quot;, nil
}

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Please note the function signature. The function must return &lt;code&gt;error&lt;/code&gt; as the second return value. Otherwise
the library will have issues.&lt;/p&gt;

&lt;p&gt;In our case, we will be building a single executable from the worker code. So the package is called main. Now
that we have a function, let&amp;rsquo;s write the worker. Create a file named &lt;code&gt;main.go&lt;/code&gt; and put the following contents:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main

import (
	machinery &amp;quot;github.com/RichardKnop/machinery/v1&amp;quot;
	&amp;quot;github.com/RichardKnop/machinery/v1/config&amp;quot;
	&amp;quot;github.com/RichardKnop/machinery/v1/errors&amp;quot;
)

func main() {

	var cnf = config.Config{
		Broker:        &amp;quot;redis://127.0.0.1:6379&amp;quot;,
		ResultBackend: &amp;quot;redis://127.0.0.1:6379&amp;quot;,
	}

	server, err := machinery.NewServer(&amp;amp;cnf)
	if err != nil {
		errors.Fail(err, &amp;quot;Could not create server&amp;quot;)
	}

	server.RegisterTask(&amp;quot;Say&amp;quot;, Say)

	worker := server.NewWorker(&amp;quot;worker-1&amp;quot;)
	err = worker.Launch()
	if err != nil {
		errors.Fail(err, &amp;quot;Could not launch worker!&amp;quot;)
	}

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The code is quite simple. We create a config object by passing the &lt;code&gt;Broker&lt;/code&gt; and &lt;code&gt;ResultBackend&lt;/code&gt; values. We are
using Redis here and the redis server is running on our machine. Please make sure the redis server is up and
running on that address. Otherwise, change the address to point to a running redis instance.&lt;/p&gt;

&lt;p&gt;Then we construct a server out of the configuration and register the task with the &lt;code&gt;RegisterTask&lt;/code&gt; method. We
pass a name and the corresponding function to execute for that task. It becomes simpler if we use the function
as the task name. Once the task is registered, we need to create one or more worker processes. Here we create a
new worker instance by calling &lt;code&gt;NewWorker&lt;/code&gt; method on the server. We pass a worker name so we can identify it
later on (for example in the logs). We then &lt;code&gt;Launch&lt;/code&gt; the worker. The worker starts up and connects to our redis
server. It then subscribes to appropriate channels to start listenning to task requests.&lt;/p&gt;

&lt;p&gt;That&amp;rsquo;s all we need to do to create a task and worker.&lt;/p&gt;

&lt;h3 id=&#34;requesting-sending-tasks&#34;&gt;Requesting / Sending Tasks&lt;/h3&gt;

&lt;p&gt;Now from another process (say from a running web application), on a certain ocassion, we want to run a background
task. Here we will see how we can send task requests.&lt;/p&gt;

&lt;p&gt;In our root directory, let&amp;rsquo;s create another &lt;code&gt;main.go&lt;/code&gt; file and &lt;code&gt;main&lt;/code&gt; function to send the tasks.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main

import (
	machinery &amp;quot;github.com/RichardKnop/machinery/v1&amp;quot;
	&amp;quot;github.com/RichardKnop/machinery/v1/config&amp;quot;
	&amp;quot;github.com/RichardKnop/machinery/v1/errors&amp;quot;
	&amp;quot;github.com/RichardKnop/machinery/v1/signatures&amp;quot;
)

func main() {

	var cnf = config.Config{
		Broker:        &amp;quot;redis://127.0.0.1:6379&amp;quot;,
		ResultBackend: &amp;quot;redis://127.0.0.1:6379&amp;quot;,
	}

	server, err := machinery.NewServer(&amp;amp;cnf)
	if err != nil {
		errors.Fail(err, &amp;quot;Can not create server!&amp;quot;)
	}

	sayTask := signatures.TaskSignature{
		Name: &amp;quot;Say&amp;quot;,
		Args: []signatures.TaskArg{
			signatures.TaskArg{
				Type:  &amp;quot;string&amp;quot;,
				Value: &amp;quot;masnun&amp;quot;,
			},
		},
	}

	server.SendTask(&amp;amp;sayTask)

}

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you look carefully, up to the server creation, the code is same. We define a config and create a server. Then we
define a task signature. We need to define task signatures to request task executions. In the task signature,
we need to pass the &lt;code&gt;Name&lt;/code&gt; of the task and a list of arguments as &lt;code&gt;Args&lt;/code&gt;. The args will be of &lt;code&gt;TaskArg&lt;/code&gt; type. Each
&lt;code&gt;TaskArg&lt;/code&gt; need to set the &lt;code&gt;Type&lt;/code&gt; and the &lt;code&gt;Value&lt;/code&gt;. These arguments will be passed along to our function when the worker
receives this request.&lt;/p&gt;

&lt;p&gt;To queue a task, we use the &lt;code&gt;SendTask&lt;/code&gt; method and pass a pointer to our &lt;code&gt;TaskSignature&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&#34;tying-it-out&#34;&gt;Tying it out!&lt;/h3&gt;

&lt;p&gt;Make sure the redis server is running. In case it is not, run it.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;redis-server
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Once redis is running, build and run the worker.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cd worker
go build
./worker
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Once the worker starts up, you should see some messages like these:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;machinery: worker.go:27: Launching a worker with the following settings:
machinery: worker.go:28: - Broker: redis://127.0.0.1:6379
machinery: worker.go:29: - ResultBackend: redis://127.0.0.1:6379
machinery: worker.go:30: - Exchange:
machinery: worker.go:31: - ExchangeType:
machinery: worker.go:32: - DefaultQueue:
machinery: worker.go:33: - BindingKey:
machinery: redis.go:86: [*] Waiting for messages. To exit press CTRL+C
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we need to build the program that will send tasks to the queue. Open a new terminal window and
navigate to the project root. Build the main program and run it.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;go build -o main
./main
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That should queue the task. Now switch to the worker process and check the output. If everything goes right,
we will see some output like:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;machinery: redis.go:211: Received new message: {&amp;quot;UUID&amp;quot;:&amp;quot;task_c39f7e99-df4d-443a-ad21-3481260b34fb&amp;quot;,&amp;quot;Name&amp;quot;:&amp;quot;Say&amp;quot;,&amp;quot;RoutingKey&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;GroupUUID&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;GroupTaskCount&amp;quot;:0,&amp;quot;Args&amp;quot;:[{&amp;quot;Type&amp;quot;:&amp;quot;string&amp;quot;,&amp;quot;Value&amp;quot;:&amp;quot;masnun&amp;quot;}],&amp;quot;Headers&amp;quot;:null,&amp;quot;Immutable&amp;quot;:false,&amp;quot;OnSuccess&amp;quot;:null,&amp;quot;OnError&amp;quot;:null,&amp;quot;ChordCallback&amp;quot;:null}
machinery: worker.go:110: Processed task_c39f7e99-df4d-443a-ad21-3481260b34fb. Result = Hello masnun!
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Since we are using a &lt;code&gt;ResultBackend&lt;/code&gt; too, we can check the state and retrieve the task results.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;
asyncResult, err := server.SendTask(&amp;amp;sayTask)

taskState := asyncResult.GetState()
fmt.Printf(&amp;quot;Current state of %v task is:\n&amp;quot;, taskState.TaskUUID)
fmt.Println(taskState.State)

result, err := asyncResult.Get()
fmt.Println(result.Interface())
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(My example code on Github does not include this part, it would be a good self practice to try these out ourselves,
no?)&lt;/p&gt;

&lt;p&gt;The machinery library has some other cool features too. Do checkout the github repo for in depth documentation
and code samples.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Getting Help Interactively in Python</title>
      <link>http://masnun.rocks/2016/11/01/getting-help-interactively-in-python/</link>
      <pubDate>Tue, 01 Nov 2016 17:00:51 +0600</pubDate>
      
      <guid>http://masnun.rocks/2016/11/01/getting-help-interactively-in-python/</guid>
      <description>

&lt;p&gt;Working with a module that you&amp;rsquo;re not familiar with? No internet? Somehow the docs are not accessible?
Or simply feeling adventourous? Python has you covered. There are a few ways to get
help Interactively. In this post, we will try a few of them.&lt;/p&gt;

&lt;h3 id=&#34;the-dir-built-in&#34;&gt;The &lt;code&gt;dir&lt;/code&gt; built-in&lt;/h3&gt;

&lt;p&gt;The &lt;code&gt;dir&lt;/code&gt; built in is a very helpful one. If you call it without any arguments, that is just
&lt;code&gt;dir()&lt;/code&gt;, it will return the names available in the current scope. When passed with an argument,
it would display the available attributes of the passed object (inherited or it&amp;rsquo;s own).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt;&amp;gt;&amp;gt; import os
&amp;gt;&amp;gt;&amp;gt; dir(os)
[&#39;CLD_CONTINUED&#39;, &#39;CLD_DUMPED&#39;, &#39;CLD_EXITED&#39;, &#39;CLD_TRAPPED&#39;, &#39;EX_CANTCREAT&#39;, &#39;EX_CONFIG&#39;, &#39;EX_DATAERR&#39;, &#39;EX_IOERR&#39;, &#39;EX_NOHOST&#39;, &#39;EX_NOINPUT&#39;, &#39;EX_NOPERM&#39;, &#39;EX_NOUSER&#39;, &#39;EX_OK&#39;, &#39;EX_OSERR&#39;, &#39;EX_OSFILE&#39;, &#39;EX_PROTOCOL&#39;, &#39;EX_SOFTWARE&#39;, &#39;EX_TEMPFAIL&#39;, &#39;EX_UNAVAILABLE&#39;, &#39;EX_USAGE&#39;, &#39;F_LOCK&#39;, &#39;F_OK&#39;, &#39;F_TEST&#39;, &#39;F_TLOCK&#39;, &#39;F_ULOCK&#39;, &#39;MutableMapping&#39;, &#39;NGROUPS_MAX&#39;, &#39;O_ACCMODE&#39;, &#39;O_APPEND&#39;, &#39;O_ASYNC&#39;, &#39;O_CLOEXEC&#39;, &#39;O_CREAT&#39;, &#39;O_DIRECTORY&#39;, &#39;O_DSYNC&#39;, &#39;O_EXCL&#39;, &#39;O_EXLOCK&#39;, &#39;O_NDELAY&#39;, &#39;O_NOCTTY&#39;, &#39;O_NOFOLLOW&#39;, &#39;O_NONBLOCK&#39;, &#39;O_RDONLY&#39;, &#39;O_RDWR&#39;, &#39;O_SHLOCK&#39;, &#39;O_SYNC&#39;, &#39;O_TRUNC&#39;, &#39;O_WRONLY&#39;, &#39;PRIO_PGRP&#39;, &#39;PRIO_PROCESS&#39;, &#39;PRIO_USER&#39;, &#39;P_ALL&#39;, &#39;P_NOWAIT&#39;, &#39;P_NOWAITO&#39;, &#39;P_PGID&#39;, &#39;P_PID&#39;, &#39;P_WAIT&#39;, &#39;RTLD_GLOBAL&#39;, &#39;RTLD_LAZY&#39;, &#39;RTLD_LOCAL&#39;, &#39;RTLD_NODELETE&#39;, &#39;RTLD_NOLOAD&#39;, &#39;RTLD_NOW&#39;, &#39;R_OK&#39;, &#39;SCHED_FIFO&#39;, &#39;SCHED_OTHER&#39;, &#39;SCHED_RR&#39;, &#39;SEEK_CUR&#39;, &#39;SEEK_END&#39;, &#39;SEEK_SET&#39;, &#39;ST_NOSUID&#39;, &#39;ST_RDONLY&#39;, &#39;TMP_MAX&#39;, &#39;WCONTINUED&#39;, &#39;WCOREDUMP&#39;, &#39;WEXITED&#39;, &#39;WEXITSTATUS&#39;, &#39;WIFCONTINUED&#39;, &#39;WIFEXITED&#39;, &#39;WIFSIGNALED&#39;, &#39;WIFSTOPPED&#39;, &#39;WNOHANG&#39;, &#39;WNOWAIT&#39;, &#39;WSTOPPED&#39;, &#39;WSTOPSIG&#39;, &#39;WTERMSIG&#39;, &#39;WUNTRACED&#39;, &#39;W_OK&#39;, &#39;X_OK&#39;, &#39;_Environ&#39;, &#39;__all__&#39;, &#39;__builtins__&#39;, &#39;__cached__&#39;, &#39;__doc__&#39;, &#39;__file__&#39;, &#39;__loader__&#39;, &#39;__name__&#39;, &#39;__package__&#39;, &#39;__spec__&#39;, &#39;_execvpe&#39;, &#39;_exists&#39;, &#39;_exit&#39;, &#39;_fwalk&#39;, &#39;_get_exports_list&#39;, &#39;_putenv&#39;, &#39;_spawnvef&#39;, &#39;_unsetenv&#39;, &#39;_wrap_close&#39;, &#39;abort&#39;, &#39;access&#39;, &#39;altsep&#39;, &#39;chdir&#39;, &#39;chflags&#39;, &#39;chmod&#39;, &#39;chown&#39;, &#39;chroot&#39;, &#39;close&#39;, &#39;closerange&#39;, &#39;confstr&#39;, &#39;confstr_names&#39;, &#39;cpu_count&#39;, &#39;ctermid&#39;, &#39;curdir&#39;, &#39;defpath&#39;, &#39;device_encoding&#39;, &#39;devnull&#39;, &#39;dup&#39;, &#39;dup2&#39;, &#39;environ&#39;, &#39;environb&#39;, &#39;errno&#39;, &#39;error&#39;, &#39;execl&#39;, &#39;execle&#39;, &#39;execlp&#39;, &#39;execlpe&#39;, &#39;execv&#39;, &#39;execve&#39;, &#39;execvp&#39;, &#39;execvpe&#39;, &#39;extsep&#39;, &#39;fchdir&#39;, &#39;fchmod&#39;, &#39;fchown&#39;, &#39;fdopen&#39;, &#39;fork&#39;, &#39;forkpty&#39;, &#39;fpathconf&#39;, &#39;fsdecode&#39;, &#39;fsencode&#39;, &#39;fstat&#39;, &#39;fstatvfs&#39;, &#39;fsync&#39;, &#39;ftruncate&#39;, &#39;fwalk&#39;, &#39;get_blocking&#39;, &#39;get_exec_path&#39;, &#39;get_inheritable&#39;, &#39;get_terminal_size&#39;, &#39;getcwd&#39;, &#39;getcwdb&#39;, &#39;getegid&#39;, &#39;getenv&#39;, &#39;getenvb&#39;, &#39;geteuid&#39;, &#39;getgid&#39;, &#39;getgrouplist&#39;, &#39;getgroups&#39;, &#39;getloadavg&#39;, &#39;getlogin&#39;, &#39;getpgid&#39;, &#39;getpgrp&#39;, &#39;getpid&#39;, &#39;getppid&#39;, &#39;getpriority&#39;, &#39;getsid&#39;, &#39;getuid&#39;, &#39;initgroups&#39;, &#39;isatty&#39;, &#39;kill&#39;, &#39;killpg&#39;, &#39;lchflags&#39;, &#39;lchmod&#39;, &#39;lchown&#39;, &#39;linesep&#39;, &#39;link&#39;, &#39;listdir&#39;, &#39;lockf&#39;, &#39;lseek&#39;, &#39;lstat&#39;, &#39;major&#39;, &#39;makedev&#39;, &#39;makedirs&#39;, &#39;minor&#39;, &#39;mkdir&#39;, &#39;mkfifo&#39;, &#39;mknod&#39;, &#39;name&#39;, &#39;nice&#39;, &#39;open&#39;, &#39;openpty&#39;, &#39;pardir&#39;, &#39;path&#39;, &#39;pathconf&#39;, &#39;pathconf_names&#39;, &#39;pathsep&#39;, &#39;pipe&#39;, &#39;popen&#39;, &#39;pread&#39;, &#39;putenv&#39;, &#39;pwrite&#39;, &#39;read&#39;, &#39;readlink&#39;, &#39;readv&#39;, &#39;remove&#39;, &#39;removedirs&#39;, &#39;rename&#39;, &#39;renames&#39;, &#39;replace&#39;, &#39;rmdir&#39;, &#39;scandir&#39;, &#39;sched_get_priority_max&#39;, &#39;sched_get_priority_min&#39;, &#39;sched_yield&#39;, &#39;sendfile&#39;, &#39;sep&#39;, &#39;set_blocking&#39;, &#39;set_inheritable&#39;, &#39;setegid&#39;, &#39;seteuid&#39;, &#39;setgid&#39;, &#39;setgroups&#39;, &#39;setpgid&#39;, &#39;setpgrp&#39;, &#39;setpriority&#39;, &#39;setregid&#39;, &#39;setreuid&#39;, &#39;setsid&#39;, &#39;setuid&#39;, &#39;spawnl&#39;, &#39;spawnle&#39;, &#39;spawnlp&#39;, &#39;spawnlpe&#39;, &#39;spawnv&#39;, &#39;spawnve&#39;, &#39;spawnvp&#39;, &#39;spawnvpe&#39;, &#39;st&#39;, &#39;stat&#39;, &#39;stat_float_times&#39;, &#39;stat_result&#39;, &#39;statvfs&#39;, &#39;statvfs_result&#39;, &#39;strerror&#39;, &#39;supports_bytes_environ&#39;, &#39;supports_dir_fd&#39;, &#39;supports_effective_ids&#39;, &#39;supports_fd&#39;, &#39;supports_follow_symlinks&#39;, &#39;symlink&#39;, &#39;sync&#39;, &#39;sys&#39;, &#39;sysconf&#39;, &#39;sysconf_names&#39;, &#39;system&#39;, &#39;tcgetpgrp&#39;, &#39;tcsetpgrp&#39;, &#39;terminal_size&#39;, &#39;times&#39;, &#39;times_result&#39;, &#39;truncate&#39;, &#39;ttyname&#39;, &#39;umask&#39;, &#39;uname&#39;, &#39;uname_result&#39;, &#39;unlink&#39;, &#39;unsetenv&#39;, &#39;urandom&#39;, &#39;utime&#39;, &#39;wait&#39;, &#39;wait3&#39;, &#39;wait4&#39;, &#39;waitpid&#39;, &#39;walk&#39;, &#39;write&#39;, &#39;writev&#39;]
&amp;gt;&amp;gt;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Coupled with &lt;code&gt;getattr&lt;/code&gt;, you can actually write your own custom utilities to better inspect objects.&lt;/p&gt;

&lt;h3 id=&#34;the-help-built-in&#34;&gt;The &lt;code&gt;help&lt;/code&gt; built-in&lt;/h3&gt;

&lt;p&gt;I guess I don&amp;rsquo;t have to tell you how &lt;code&gt;help&lt;/code&gt;-ful this one can be?&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Did you know the &lt;code&gt;help&lt;/code&gt; built in is based on &lt;code&gt;pydoc.help&lt;/code&gt;?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;If you just call &lt;code&gt;help&lt;/code&gt;  without any arguments, it will launch an interactive help prompt
where you can just type in names and it will display help for that. Here&amp;rsquo;s an example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt;&amp;gt;&amp;gt; help()

Welcome to Python 3.5&#39;s help utility!

If this is your first time using Python, you should definitely check out
the tutorial on the Internet at http://docs.python.org/3.5/tutorial/.

Enter the name of any module, keyword, or topic to get help on writing
Python programs and using Python modules.  To quit this help utility and
return to the interpreter, just type &amp;quot;quit&amp;quot;.

To get a list of available modules, keywords, symbols, or topics, type
&amp;quot;modules&amp;quot;, &amp;quot;keywords&amp;quot;, &amp;quot;symbols&amp;quot;, or &amp;quot;topics&amp;quot;.  Each module also comes
with a one-line summary of what it does; to list the modules whose name
or summary contain a given string such as &amp;quot;spam&amp;quot;, type &amp;quot;modules spam&amp;quot;.

help&amp;gt; list

help&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When you type in &lt;code&gt;list&lt;/code&gt; and hit enter, it will show you the docs for the &lt;code&gt;list&lt;/code&gt; built in. To quit, press
&lt;code&gt;q&lt;/code&gt;. As described in the text above, typing in &amp;ldquo;modules&amp;rdquo;, &amp;ldquo;keywords&amp;rdquo; etc will list what is available.&lt;/p&gt;

&lt;p&gt;Interestingly the help functionality is built on top of &lt;code&gt;pydoc&lt;/code&gt; so it will be able to help you with most
of the installed modules (even the third party ones) as long as the modules have doctstrings available.
Brilliant, no?&lt;/p&gt;

&lt;p&gt;Now if you call the &lt;code&gt;help&lt;/code&gt; callable with an argument, it will display help for that item. The above example
for viewing the docs for &lt;code&gt;list&lt;/code&gt; can be done this way too:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt;&amp;gt;&amp;gt; help(list)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Neat, huh?&lt;/p&gt;

&lt;h3 id=&#34;using-the-pydoc-module&#34;&gt;Using the &lt;code&gt;pydoc&lt;/code&gt; Module&lt;/h3&gt;

&lt;p&gt;In the previous section, we mentioned &lt;code&gt;pydoc&lt;/code&gt;. From the name, you can probably guess what it does. Just to be
certain, let&amp;rsquo;s try this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt;&amp;gt;&amp;gt; import pydoc
&amp;gt;&amp;gt;&amp;gt; help(pydoc)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As you can read in there, the &lt;code&gt;pydoc&lt;/code&gt; module generates documentation in html or text format for interactive
usages (like in the previous section). It can read Python source files, parse the docstrings and generate
helpful information for us. Pydoc module comes with your Python installation. So it is always available to you.&lt;/p&gt;

&lt;p&gt;There are some interesting use cases of this module. You can run it from the command line. Just use
&lt;code&gt;pydoc &amp;lt;name&amp;gt;&lt;/code&gt; where the &lt;code&gt;&amp;lt;name&amp;gt;&lt;/code&gt; is the name of a function, module, class etc. It will display
the same interactive, generated docs we get from &lt;code&gt;help(&amp;lt;name&amp;gt;)&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;And then &lt;code&gt;pydoc -k &amp;lt;keyword&amp;gt;&lt;/code&gt; would search the keyword in the available modules&amp;rsquo; synopsis.&lt;/p&gt;

&lt;p&gt;If you would like to browse the docs on a web browser, you can run &lt;code&gt;pydoc -b&lt;/code&gt; and it will run a
server and open your browser, pointing to the address of the server. If you would like to set the port
yourself, use &lt;code&gt;pydoc -p &amp;lt;port&amp;gt;&lt;/code&gt; and then in the prompt, type &amp;ldquo;b&amp;rdquo; to open the browser. You can browse
the docs and search as needed.&lt;/p&gt;

&lt;h3 id=&#34;the-inspect-module&#34;&gt;The &lt;code&gt;inspect&lt;/code&gt; Module&lt;/h3&gt;

&lt;p&gt;The &lt;code&gt;inspect&lt;/code&gt; module has some interesting use cases too. It can help us know more about different objects
in runtime.&lt;/p&gt;

&lt;p&gt;The following functions check for object types:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ismodule()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;isclass()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ismethod()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;isfunction()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;isgeneratorfunction()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;isgenerator()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;istraceback()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;isframe()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;iscode()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;isbuiltin()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;isroutine()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We can use the &lt;code&gt;getmembers()&lt;/code&gt; function to get all the members of an object, class or module. We can filter
the members by passing one of the above functions as the second argument.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt;&amp;gt;&amp;gt; len(inspect.getmembers(os))
284
&amp;gt;&amp;gt;&amp;gt; len(inspect.getmembers(os, inspect.isclass))
9
&amp;gt;&amp;gt;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;getdoc&lt;/code&gt; function can be used to retrieve available documentation from an object.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt;&amp;gt;&amp;gt; inspect.getdoc(list)
&amp;quot;list() -&amp;gt; new empty list\nlist(iterable) -&amp;gt; new list initialized from iterable&#39;s items&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The inspect module has some other cool functions too. Do check them out. And of course, you know how! ;-)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt;&amp;gt;&amp;gt; import inspect
&amp;gt;&amp;gt;&amp;gt; help(inspect)
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Xiaomi Phones: Fixing Notification Problems</title>
      <link>http://masnun.rocks/2016/10/20/xiaomi-fix-notification-issues/</link>
      <pubDate>Thu, 20 Oct 2016 03:34:09 +0600</pubDate>
      
      <guid>http://masnun.rocks/2016/10/20/xiaomi-fix-notification-issues/</guid>
      <description>

&lt;p&gt;Xiaomi Phones are pretty good. I have a Redmi Note 3 Pro and I am quite loving
the experience. However, I did notice some of the apps were not receiving
notifications properly. This includes the &amp;ldquo;Inbox&amp;rdquo; app from Google and &amp;ldquo;Slack&amp;rdquo;
which I need almost all day. I was getting concerned. Luckily, after some googling
I found several fixes on different forums. I will quickly go through them in this
post.&lt;/p&gt;

&lt;h3 id=&#34;enable-autostart&#34;&gt;Enable Autostart&lt;/h3&gt;

&lt;p&gt;Enabling autostart fixes the notification issue for most people. To make sure that
notifications work for a particular app, enable that app to &amp;ldquo;autostart&amp;rdquo;. This can
be done from the &amp;ldquo;Permissions&amp;rdquo; section in the &amp;ldquo;Security&amp;rdquo; app. Alternatively, this
can also be accessed from the &amp;ldquo;Permissions&amp;rdquo; sub menu in the &amp;ldquo;Device&amp;rdquo; section under
the &amp;ldquo;Settings&amp;rdquo; app.&lt;/p&gt;

&lt;p&gt;You can read a step by step tutorial on this here on:
&lt;a href=&#34;http://xiaomininja.com/2015/08/10/miui-tip-enable-autostart-to-never-miss-a-notification-again/&#34;&gt;Xiaomi Ninja&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Or you can follow this video:&lt;/p&gt;

&lt;p&gt;&lt;iframe width=&#34;640&#34; height=&#34;360&#34; src=&#34;https://www.youtube.com/embed/wZESXVSxByY&#34; frameborder=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;&lt;/p&gt;

&lt;h3 id=&#34;lock-apps-to-memory&#34;&gt;Lock Apps to Memory&lt;/h3&gt;

&lt;p&gt;This is another good solution that would work. In the task manager, slightly pull down
 an open app and you will see the &amp;ldquo;Lock&amp;rdquo; option. Locked apps aren&amp;rsquo;t cleared from memory
 and they keep running. So notifications work quite fine!&lt;/p&gt;

&lt;p&gt;Locking apps also come very handy if you don&amp;rsquo;t want to autostart a particular app,
 you just need it open for certain period of time. For example, I can choose to have
 Slack open only during my work hours.&lt;/p&gt;

&lt;h3 id=&#34;managing-background-activities&#34;&gt;Managing Background Activities&lt;/h3&gt;

&lt;p&gt;Go to: &lt;code&gt;Settings &amp;gt; Battery &amp;amp; Performance &amp;gt; Manage Apps Battery Use&lt;/code&gt; and &lt;code&gt;Choose Apps&lt;/code&gt;.
For the apps you want, select &amp;ldquo;No Restrictions&amp;rdquo;. Setting this would tell MIUI not to
terminate/interrupt any background processes from those apps.&lt;/p&gt;

&lt;h3 id=&#34;remember-to-restart&#34;&gt;Remember to Restart&lt;/h3&gt;

&lt;p&gt;Once you have made the changes, restart the phone. Specially after enabling autostart.
Now test out the notifications and see if they work fine.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Async Python:  The Different Forms of Concurrency</title>
      <link>http://masnun.rocks/2016/10/06/async-python-the-different-forms-of-concurrency/</link>
      <pubDate>Thu, 06 Oct 2016 12:10:03 +0600</pubDate>
      
      <guid>http://masnun.rocks/2016/10/06/async-python-the-different-forms-of-concurrency/</guid>
      <description>

&lt;p&gt;With the advent of Python 3 the way we&amp;rsquo;re hearing a lot of buzz about &amp;ldquo;async&amp;rdquo; and &amp;ldquo;concurrency&amp;rdquo;, one
might simply assume that Python recently introduced these concepts/capabilities. But that would be quite
far from the truth. We have had async and concurrent operations for quite some times now. Also many
beginners may think that &lt;code&gt;asyncio&lt;/code&gt; is the only/best way to do async/concurrent operations. In this post
we shall explore the different ways we can achieve concurrency and the benefits/drawbacks of them.&lt;/p&gt;

&lt;h3 id=&#34;defining-the-terms&#34;&gt;Defining The Terms&lt;/h3&gt;

&lt;p&gt;Before we dive into the technical aspects, it is essential to have some basic understanding of the terms
frequently used in this context.&lt;/p&gt;

&lt;h4 id=&#34;sync-vs-async&#34;&gt;Sync vs Async&lt;/h4&gt;

&lt;p&gt;In Syncrhonous operations, the tasks are executed in sync, one after one. In asynchronous operations,
tasks may start and complete independent of each other. One async task may start and continue running
while the execution moves on to a new task. Async tasks don&amp;rsquo;t block (make the execution wait for it&amp;rsquo;s
completion) operations and usually run in the background.&lt;/p&gt;

&lt;p&gt;For example, you have to call a travel agency to book for your next vacation. And you need to send an
email to your boss before you go on the tour. In synchronous fashion, you would first call the travel
agency, if they put you on hold for a moment, you keep waiting and waiting. Once it&amp;rsquo;s done, you start
writing the email to your boss. Here you complete one task after another. But if you be clever and
while you are waiting on hold, you could start writing up the email, when they talk to you, you pause
writing the email, talk to them and then resume the email writing. You could also ask a friend to
make the call while you finish that email. This is asynchronicity. Tasks don&amp;rsquo;t block one another.&lt;/p&gt;

&lt;h4 id=&#34;concurrency-and-parallelism&#34;&gt;Concurrency and Parallelism&lt;/h4&gt;

&lt;p&gt;Concurrency implies that two tasks make progress together. In our previous example, when we
considered the async example, we were making progress on both the call with the travel agent and
writing the email. This is concurrency.&lt;/p&gt;

&lt;p&gt;When we talked about taking help from a friend with the call, in that case both tasks would be running
in parallel.&lt;/p&gt;

&lt;p&gt;Parallelism is in fact a form of concurrency. But parallelism is hardware dependent. For example if
there&amp;rsquo;s only one core in the CPU, two operations can&amp;rsquo;t really run in parallel. They just share time
slices from the same core. This is concurrency but not parallelism. But when we have multiple cores,
we can actually run two or more operations (depending on the number of cores) in parallel.&lt;/p&gt;

&lt;h4 id=&#34;quick-recap&#34;&gt;Quick Recap&lt;/h4&gt;

&lt;p&gt;So this is what we have realized so far:&lt;/p&gt;

&lt;ul&gt;
    &lt;li&gt; &lt;b&gt;Sync:&lt;/b&gt; Blocking operations.&lt;/li&gt;
    &lt;li&gt; &lt;b&gt;Async:&lt;/b&gt; Non blocking operations.&lt;/li&gt;
    &lt;li&gt; &lt;b&gt;Concurrency:&lt;/b&gt; Making progress together.&lt;/li&gt;
    &lt;li&gt; &lt;b&gt;Parallelism:&lt;/b&gt; Making progress in parallel.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
    &lt;em&gt;Parallelism implies Concurrency. But Concurrency doesn&amp;rsquo;t always mean Parallelism.&lt;/em&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;&lt;br/&gt;&lt;/p&gt;

&lt;h3 id=&#34;threads-processes&#34;&gt;Threads &amp;amp; Processes&lt;/h3&gt;

&lt;p&gt;Python has had &lt;strong&gt;Threads&lt;/strong&gt; for a very long time. Threads allow us to run our operations concurrently. But there was/is a problem with
the &lt;strong&gt;Global Interpreter Lock (GIL)&lt;/strong&gt; for which the threading could not provide true parallelism. However, with &lt;strong&gt;multiprocessing&lt;/strong&gt;,
it is now possible to leverage multiple cores with Python.&lt;/p&gt;

&lt;h4 id=&#34;threads&#34;&gt;Threads&lt;/h4&gt;

&lt;p&gt;Let&amp;rsquo;s see a quick example. In the following code, the &lt;code&gt;worker&lt;/code&gt; function will be run on multiple threads, asynchronously and
concurrently.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import threading
import time
import random


def worker(number):
    sleep = random.randrange(1, 10)
    time.sleep(sleep)
    print(&amp;quot;I am Worker {}, I slept for {} seconds&amp;quot;.format(number, sleep))


for i in range(5):
    t = threading.Thread(target=worker, args=(i,))
    t.start()

print(&amp;quot;All Threads are queued, let&#39;s see when they finish!&amp;quot;)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here&amp;rsquo;s a sample output from a run on my machine:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;$ python thread_test.py
All Threads are queued, let&#39;s see when they finish!
I am Worker 1, I slept for 1 seconds
I am Worker 3, I slept for 4 seconds
I am Worker 4, I slept for 5 seconds
I am Worker 2, I slept for 7 seconds
I am Worker 0, I slept for 9 seconds
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So you can see we start 5 threads, they make progress together and when we start the threads (and thus executing the worker function),
the operation does not wait for the threads to complete before moving on to the next print statement. So this is an async operation.&lt;/p&gt;

&lt;p&gt;In our example, we passed a function to the &lt;code&gt;Thread&lt;/code&gt; constructor. But if we wanted we could also subclass it and implement the code
as a method (in a more OOP way).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Further Reading:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;To know about Threads in details, you can follow these resources:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://pymotw.com/3/threading/index.html&#34;&gt;https://pymotw.com/3/threading/index.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;global-interpreter-lock-gil&#34;&gt;Global Interpreter Lock (GIL)&lt;/h4&gt;

&lt;p&gt;The Global Interpreter Lock aka GIL was introduced to make CPython&amp;rsquo;s memory handling easier and to allow better integrations with C
(for example the extensions). The GIL is a locking mechanism that the Python interpreter runs only one thread at a time. That is
only one thread can execute Python byte code at any given time. This GIL makes sure that multiple threads &lt;strong&gt;DO NOT&lt;/strong&gt; run in parallel.&lt;/p&gt;

&lt;p&gt;Quick facts about the GIL:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;One thread can run at a time.&lt;/li&gt;
&lt;li&gt;The Python Interpreter switches between threads to allow concurrency.&lt;/li&gt;
&lt;li&gt;The GIL is only applicable to CPython (the defacto implementation). Other implementations like Jython, IronPython don&amp;rsquo;t have GIL.&lt;/li&gt;
&lt;li&gt;GIL makes single threaded programs fast.&lt;/li&gt;
&lt;li&gt;For I/O bound operations, GIL usually doesn&amp;rsquo;t harm much.&lt;/li&gt;
&lt;li&gt;GIL makes it easy to integrate non thread safe C libraries, thansk to the GIL, we have many high performance extensions/modules written in C.&lt;/li&gt;
&lt;li&gt;For CPU bound tasks, the interpreter checks between &lt;code&gt;N&lt;/code&gt; ticks and switches threads. So one thread does not block others.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Many people see the &lt;code&gt;GIL&lt;/code&gt; as a weakness. I see it as a blessing since it has made libraries like NumPy, SciPy possible which have
taken Python an unique position in the scientific communities.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Further Reading:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;These resources can help dive deeper into the GIL:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.dabeaz.com/python/UnderstandingGIL.pdf&#34;&gt;http://www.dabeaz.com/python/UnderstandingGIL.pdf&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;processes&#34;&gt;Processes&lt;/h4&gt;

&lt;p&gt;To get parallelism, Python introduced the &lt;code&gt;multiprocessing&lt;/code&gt; module which provides APIs which will feel very similar if you have used
Threading before.&lt;/p&gt;

&lt;p&gt;In fact, we will just go and change our previous example. Here&amp;rsquo;s the modified version that uses &lt;code&gt;Process&lt;/code&gt; instead of &lt;code&gt;Thread&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;
import multiprocessing
import time
import random


def worker(number):
    sleep = random.randrange(1, 10)
    time.sleep(sleep)
    print(&amp;quot;I am Worker {}, I slept for {} seconds&amp;quot;.format(number, sleep))


for i in range(5):
    t = multiprocessing.Process(target=worker, args=(i,))
    t.start()

print(&amp;quot;All Processes are queued, let&#39;s see when they finish!&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So what&amp;rsquo;s changed? I just imported the &lt;code&gt;multiprocessing&lt;/code&gt; module instead of &lt;code&gt;threading&lt;/code&gt;. And then instead of &lt;code&gt;Thread&lt;/code&gt;, I used
&lt;code&gt;Process&lt;/code&gt;. That&amp;rsquo;s it, really! Now instead of multi threading, we are using multiple processes which are running on different core
of your CPU (assuming you have multiple cores).&lt;/p&gt;

&lt;p&gt;With the &lt;code&gt;Pool&lt;/code&gt; class, we can also distribute one function execution across multiple processes for different input values. If we
take the example from the official docs:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from multiprocessing import Pool

def f(x):
    return x*x

if __name__ == &#39;__main__&#39;:
    p = Pool(5)
    print(p.map(f, [1, 2, 3]))

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here, instead of iterating over the list of values and calling &lt;code&gt;f&lt;/code&gt; on them one by one, we are actually running the function on
different processes. One process executes &lt;code&gt;f(1)&lt;/code&gt;, another runs &lt;code&gt;f(2)&lt;/code&gt; and another runs &lt;code&gt;f(3)&lt;/code&gt;. Finally the results are again
aggregated in a list. This would allow us to break down heavy computations into smaller parts and run them in parallel for faster
calculation.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Further Reading:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://pymotw.com/3/multiprocessing/index.html&#34;&gt;https://pymotw.com/3/multiprocessing/index.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;the-concurrent-futures-module&#34;&gt;The &lt;code&gt;concurrent.futures&lt;/code&gt; module&lt;/h4&gt;

&lt;p&gt;The &lt;code&gt;concurrent.futures&lt;/code&gt; module packs some really great stuff for writing async codes easily. My favorites are the &lt;code&gt;ThreadPoolExecutor&lt;/code&gt;
and the &lt;code&gt;ProcessPoolExecutor&lt;/code&gt;. These executors maintain a pool of threads or processes. We submit our tasks to the pool and it
runs the tasks in available thread/process. A &lt;code&gt;Future&lt;/code&gt; object is returned which we can use to query and get the result when the task
has completed.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s an example of &lt;code&gt;ThreadPoolExecutor&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from concurrent.futures import ThreadPoolExecutor
from time import sleep
 
def return_after_5_secs(message):
    sleep(5)
    return message
 
pool = ThreadPoolExecutor(3)
 
future = pool.submit(return_after_5_secs, (&amp;quot;hello&amp;quot;))
print(future.done())
sleep(5)
print(future.done())
print(future.result())
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I have a blog post on the &lt;code&gt;concurrent.futures&lt;/code&gt; module here: &lt;a href=&#34;http://masnun.com/2016/03/29/python-a-quick-introduction-to-the-concurrent-futures-module.html&#34;&gt;http://masnun.com/2016/03/29/python-a-quick-introduction-to-the-concurrent-futures-module.html&lt;/a&gt;
which might be helpful for exploring the module deeper.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Further Reading:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://pymotw.com/3/concurrent.futures/&#34;&gt;https://pymotw.com/3/concurrent.futures/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br/&gt;&lt;/p&gt;

&lt;h3 id=&#34;asyncio-why-what-and-how&#34;&gt;Asyncio - Why, What and How?&lt;/h3&gt;

&lt;p&gt;You probably have the question many people in the Python community have - What does asyncio bring new to the table? Why did we need
one more way to do async I/O? Did we not have threads and processes already? Let&amp;rsquo;s see!&lt;/p&gt;

&lt;h4 id=&#34;why-do-we-need-asyncio&#34;&gt;Why do we need asyncio?&lt;/h4&gt;

&lt;p&gt;Processes are costly to spawn. So for I/O, Threads are chosen largely. We know that I/O depends on external stuff - slow disks or
nasty network lags make I/O often unpredictable. Now, let&amp;rsquo;s assume that we are using threads for I/O bound operations. 3 threads
are doing different I/O tasks. The interpreter would need to switch between the concurrent threads and give each of them some time
in turns. Let&amp;rsquo;s call the threads - &lt;code&gt;T1&lt;/code&gt;, &lt;code&gt;T2&lt;/code&gt; and &lt;code&gt;T3&lt;/code&gt;. The three threads have started their I/O operation. &lt;code&gt;T3&lt;/code&gt; completes it first.
&lt;code&gt;T2&lt;/code&gt; and &lt;code&gt;T1&lt;/code&gt; are still waiting for I/O.  The Python interpreter switches to &lt;code&gt;T1&lt;/code&gt; but it&amp;rsquo;s still waiting. Fine, so it moves to &lt;code&gt;T2&lt;/code&gt;,
it&amp;rsquo;s still waiting and then it moves to &lt;code&gt;T3&lt;/code&gt; which is ready and executes the code. Do you see the problem here?&lt;/p&gt;

&lt;p&gt;&lt;code&gt;T3&lt;/code&gt; was ready but the interpreter switched between &lt;code&gt;T2&lt;/code&gt; and &lt;code&gt;T1&lt;/code&gt; first - that incurred switching costs  which we could have avoided
 if the interpreter first moved to &lt;code&gt;T3&lt;/code&gt;, right?&lt;/p&gt;

&lt;h4 id=&#34;what-is-asyncio&#34;&gt;What is asyncio?&lt;/h4&gt;

&lt;p&gt;Asyncio provides us an event loop along with other good stuff. The event loop tracks different I/O events and switches to
 tasks which are  ready and pauses the ones which are waiting on I/O. Thus we don&amp;rsquo;t waste time on tasks which are not ready to run
 right now.&lt;/p&gt;

&lt;p&gt;The idea is very simple. There&amp;rsquo;s an event loop. And we have functions that run async, I/O operations. We give our functions to the
 event loop and ask it to run those for us. The event loop gives us back a &lt;code&gt;Future&lt;/code&gt; object, it&amp;rsquo;s like a promise that we will get
 something back in the &lt;em&gt;future&lt;/em&gt;. We hold on to the promise, time to time check if it has a value (when we feel impatient) and finally
 when the future has a value, we use it in some other operations.&lt;/p&gt;

&lt;p&gt;Asyncio uses generators and coroutines to pause and resume tasks. You can read these posts for more details:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://masnun.com/2015/11/20/python-asyncio-future-task-and-the-event-loop.html&#34;&gt;http://masnun.com/2015/11/20/python-asyncio-future-task-and-the-event-loop.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://masnun.com/2015/11/13/python-generators-coroutines-native-coroutines-and-async-await.html&#34;&gt;http://masnun.com/2015/11/13/python-generators-coroutines-native-coroutines-and-async-await.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;how-do-we-use-asyncio&#34;&gt;How do we use asyncio?&lt;/h4&gt;

&lt;p&gt;Before we beging, let&amp;rsquo;s see example codes:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import asyncio
import datetime
import random


async def my_sleep_func():
    await asyncio.sleep(random.randint(0, 5))


async def display_date(num, loop):
    end_time = loop.time() + 50.0
    while True:
        print(&amp;quot;Loop: {} Time: {}&amp;quot;.format(num, datetime.datetime.now()))
        if (loop.time() + 1.0) &amp;gt;= end_time:
            break
        await my_sleep_func()


loop = asyncio.get_event_loop()

asyncio.ensure_future(display_date(1, loop))
asyncio.ensure_future(display_date(2, loop))

loop.run_forever()

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Please note that the &lt;code&gt;async/await&lt;/code&gt; syntax is Python 3.5+ only. if we walk through the codes:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;We have an async function &lt;code&gt;display_date&lt;/code&gt; which takes a number (as an identifier) and the event loop as parameters.&lt;/li&gt;
&lt;li&gt;The function has an infinite loop that breaks after 50 secs. But during this 50 sec period, it repeatedly prints out the time
and takes a nap. The &lt;code&gt;await&lt;/code&gt; function can wait on other async functions (coroutines) to complete.&lt;/li&gt;
&lt;li&gt;We pass the function to event loop (using the &lt;code&gt;ensure_future&lt;/code&gt; method).&lt;/li&gt;
&lt;li&gt;We start running the event loop.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Whenever the &lt;code&gt;await&lt;/code&gt; call is made, asyncio understands that the function is probably going to need some time. So it pauses the execution,
starts monitoring any I/O event related to it and allows tasks to run. When asyncio notices that paused function&amp;rsquo;s I/O is ready, it
resumes the function.&lt;/p&gt;

&lt;h3 id=&#34;making-the-right-choice&#34;&gt;Making the Right Choice&lt;/h3&gt;

&lt;p&gt;We have walked through the most popular forms of concurrency. But the question remains - when should choose which one?
It really depends on the use cases. From my experience (and reading), I tend to follow this pseudo code:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;if io_bound:
    if io_very_slow:
        print(&amp;quot;Use Asyncio&amp;quot;)
    else:
       print(&amp;quot;Use Threads&amp;quot;)
else:
    print(&amp;quot;Multi Processing&amp;quot;)

&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;CPU Bound =&amp;gt; Multi Processing&lt;/li&gt;
&lt;li&gt;I/O Bound, Fast I/O, Limited Number of Connections =&amp;gt; Multi Threading&lt;/li&gt;
&lt;li&gt;I/O Bound, Slow I/O, Many connections =&amp;gt; Asyncio&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Creating an executable file using Cython</title>
      <link>http://masnun.rocks/2016/10/01/creating-an-executable-file-using-cython/</link>
      <pubDate>Sat, 01 Oct 2016 17:27:23 +0600</pubDate>
      
      <guid>http://masnun.rocks/2016/10/01/creating-an-executable-file-using-cython/</guid>
      <description>

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Disclaimer&lt;/strong&gt;: I am quite new to Cython, if you find any part of this post is incorrect or
there are better ways to do something, I would really appreciate your feedback. Please do feel
free to leave your thoughts in the comments section :)&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;I know Cython is supposed to be used for building extensions, but I was wondering if we can
by any chance compile a Python file into executable binary using Cython? I searched on Google and found this
&lt;a target=&#34;_blank&#34; href=&#34;http://stackoverflow.com/questions/5105482/compile-main-python-program-using-cython&#34;&gt;StackOverflow&lt;/a&gt;
question. There is a detailed answer on this question which is very helpful. I tried to follow the
instructions and after (finding and ) fixing some paths, I managed to do it. I am going to write down
my experience here in case someone else finds it useful as well.&lt;/p&gt;

&lt;h3 id=&#34;embedding-the-python-interpreter&#34;&gt;Embedding the Python Interpreter&lt;/h3&gt;

&lt;p&gt;Cython compiles the Python or the Cython files into C and then compiles the C code to create the
extensions. Interestingly, Cython has a CLI switch &lt;code&gt;--embed&lt;/code&gt; whic can generate a &lt;code&gt;main&lt;/code&gt; function.
This main function embeds the Python interpreter for us. So we can just compile the C file and
get our single binary executable.&lt;/p&gt;

&lt;h3 id=&#34;getting-started&#34;&gt;Getting Started&lt;/h3&gt;

&lt;p&gt;First we need to have a Python (&lt;code&gt;.py&lt;/code&gt;) or Cython (&lt;code&gt;.pyx&lt;/code&gt;)  file ready for compilation. Let&amp;rsquo;s start with
a plain old &amp;ldquo;Hello World&amp;rdquo; example.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print(&amp;quot;Hello World!&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s convert this Python file to a C source file with embedded Python interpreter.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cython --embed -o hello_world.c hello_world.py
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It should generate a file named &lt;code&gt;hello_world.c&lt;/code&gt; in the current directory. We now compile it to an
executable.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;gcc -v -Os -I /Users/masnun/.pyenv/versions/3.5.1/include/python3.5m -L /usr/local/Frameworks/Python.framework/Versions/3.5/lib  -o test test.c  -lpython3.5  -lpthread -lm -lutil -ldl
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Please note you must have the Python source code and dynamic libraries in order to successfully compile
it. I am on OSX and I use PyEnv. So I passed the appropriate paths and it compiled fine.&lt;/p&gt;

&lt;p&gt;Now I have an executable file, which I can run:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ ./hello_world
Hello World!
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;dynamic-linking&#34;&gt;Dynamic Linking&lt;/h3&gt;

&lt;p&gt;In this case, the executable we produce is dynamically linked to our specified Python version. So this
may not be fully portable (the libraries will need to be available on target machines). But this should
work fine if we compile against common versions (for example the default version of Python or a version
easily obtainable via the package manager).&lt;/p&gt;

&lt;h3 id=&#34;including-other-modules&#34;&gt;Including Other Modules&lt;/h3&gt;

&lt;p&gt;Up untill now, I haven&amp;rsquo;t found any easy ways to include other 3rd party pure python modules (ie. &lt;code&gt;requests&lt;/code&gt;)
directly compiled into the binary. However, if I want to split my codes into multiple files,  I can
create other &lt;code&gt;.pyx&lt;/code&gt; files and use the &lt;code&gt;include&lt;/code&gt; statement with those.&lt;/p&gt;

&lt;p&gt;For example, here&amp;rsquo;s &lt;code&gt;hello.pyx&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cython&#34;&gt;cdef struct Person:
    char *name
    int age

cdef say():
    cdef Person masnun = Person(name=&amp;quot;masnun&amp;quot;, age=20)
    print(&amp;quot;Hello {}, you are {} years old!&amp;quot;.format(masnun.name.decode(&#39;utf8&#39;), masnun.age))

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And here&amp;rsquo;s my main file - &lt;code&gt;test.pyx&lt;/code&gt; -&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cython&#34;&gt;include &amp;quot;hello.pyx&amp;quot;

say()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now if I compile &lt;code&gt;test.pyx&lt;/code&gt; just like above example, it will also include the code in &lt;code&gt;hello.pyx&lt;/code&gt; and
I can call the &lt;code&gt;say&lt;/code&gt; function as if it was in &lt;code&gt;test.pyx&lt;/code&gt; itself.&lt;/p&gt;

&lt;p&gt;However, shared libraries like PyQt would have no issues - we can compile them as is. So
basically we can take any PyQt code example and compile it with Cython - it should work fine!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Can Cython make Python Great in Programming Contests?</title>
      <link>http://masnun.rocks/2016/09/28/can-cython-make-python-great-in-programming-contests/</link>
      <pubDate>Wed, 28 Sep 2016 08:00:30 +0600</pubDate>
      
      <guid>http://masnun.rocks/2016/09/28/can-cython-make-python-great-in-programming-contests/</guid>
      <description>

&lt;p&gt;Python is getting very popular as the first programming language in both home and aborad. I know many of the
Bangladeshi universities have started using Python to introduce beginners to the wonderful world of programming.
This also seems to be &lt;a target=&#34;_blank&#34; href=&#34;http://cacm.acm.org/blogs/blog-cacm/176450-python-is-now-the-most-popular-introductory-teaching-language-at-top-u-s-universities/fulltext&#34;&gt;the case&lt;/a&gt;
in the US. I have talked to a few friends from other countries and they agree to the fact that
Python is quickly becoming the language people learn first. A quick &lt;a target=&#34;_blank&#34; href=&#34;http://bfy.tw/7v1B&#34;&gt;google search&lt;/a&gt; could explain why Python is
getting so popular among the learners.&lt;/p&gt;

&lt;h3 id=&#34;python-in-programming-contests&#34;&gt;Python in Programming Contests&lt;/h3&gt;

&lt;p&gt;Recently Python has been been included in ICPC, before that Python has usually had less visibility / presence in programming
contests. And of course there are valid reasons behind that. The defacto implementation of Python - &amp;ldquo;CPython&amp;rdquo; is
quite slow. It&amp;rsquo;s a dynmaic language and that costs in terms of execution speed. C / C++ / Java is way
faster than Python and programming contests are all about speed / performance.
Python would allow you to solve problems in less lines of code but you may often hit the time limit. Despite the
limitation, people have continiously chosen Python to learn programming and solve problems on numerous programming
related websites. This might have convnced the authority to include Python in ICPC.  But we do not yet know
which flavor (read implementation) and version of Python will be available to the ICPC contestants. From
&lt;a target=&#34;_blank&#34; href=&#34;https://www.quora.com/What-do-you-think-about-the-induction-of-Python-in-ACM-ICPC-2017&#34;&gt;different&lt;/a&gt;
&lt;a target=&#34;_blank&#34; href=&#34;http://codeforces.com/blog/entry/44899&#34;&gt;sources&lt;/a&gt; I gather that Python will be supported
but the time limit issue remains - it is not guranteed that a problem can be solved within the time limit using
Python. That makes me wonder, can Cython help in such cases?&lt;/p&gt;

&lt;h3 id=&#34;introduction-to-cython&#34;&gt;Introduction to Cython&lt;/h3&gt;

&lt;p&gt;From the &lt;a target=&#34;_blank&#34; href=&#34;http://cython.org/&#34;&gt;official website&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Cython is an optimising static compiler for both the Python programming language and the extended Cython
programming language (based on Pyrex). It makes writing C extensions for Python as easy as Python itself.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;With Cython, we can add type hints to our existing Python programs and compile them to make them run faster.
But what is more awesome is the &lt;code&gt;Cython&lt;/code&gt; language - it is a superset of Python and allows us to write Python
like code which performs like C.&lt;/p&gt;

&lt;p&gt;Don&amp;rsquo;t trust my words, see for yourself in the &lt;a target=&#34;_blank&#34; href=&#34;http://docs.cython.org/en/latest/src/tutorial/cython_tutorial.html&#34;&gt;Tutorial&lt;/a&gt;
and &lt;a target=&#34;_blank&#34; href=&#34;http://docs.cython.org/en/latest/src/userguide/language_basics.html#language-basics&#34;&gt; Cython Language Basics&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;cython-is-fast&#34;&gt;Cython is Fast&lt;/h3&gt;

&lt;p&gt;When I say fast, I really mean - &lt;strong&gt;very very&lt;/strong&gt; fast.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;img src=&#34;http://masnun.rocks/images/cython-vs-c.png&#34; alt=&#34;cython vs c&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Image Source: &lt;a target=&#34;_blank&#34; href=&#34;http://ibm.co/20XSZ4F&#34;&gt;&lt;a href=&#34;http://ibm.co/20XSZ4F&#34;&gt;http://ibm.co/20XSZ4F&lt;/a&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;The above image is taken from an article from IBM Developer Works which shows how Cython compares to C in terms of speed.&lt;/p&gt;

&lt;p&gt;You can also check out these links for random benchmarks from different people:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a target=&#34;_blank&#34; href=&#34;http://www.matthiaskauer.com/2014/02/a-speed-comparison-of-python-cython-and-c/&#34;&gt;Cython beating C++&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a target=&#34;_blank&#34; href=&#34;http://prabhuramachandran.blogspot.com/2008/09/python-vs-cython-vs-d-pyd-vs-c-swig.html&#34;&gt;Cython being 30% faster than the C++&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a target=&#34;_blank&#34; href=&#34;http://aroberge.blogspot.com/2010/01/python-cython-faster-than-c.html&#34;&gt;Another Benchmark&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And finally, do try yourself and benchmark Cython against C++ and see how it performs!&lt;/p&gt;

&lt;p&gt;Bonus article &amp;ndash; &lt;a href=&#34;https://magic.io/blog/uvloop-blazing-fast-python-networking/&#34;&gt;Blazing fast Python networking&lt;/a&gt; :-)&lt;/p&gt;

&lt;h3 id=&#34;cython-is-easy-to-setup&#34;&gt;Cython is easy to Setup&lt;/h3&gt;

&lt;p&gt;OK, so is it easy to make Cython available in the contest environments? Yes, it is! The &lt;strong&gt;only&lt;/strong&gt; requirements of
Cython is that you must have a &lt;strong&gt;C Compiler&lt;/strong&gt; installed on your system along with Python. Any computer used for
contest programming is supposed to have a C compiler installed anyway.&lt;/p&gt;

&lt;p&gt;We just need one command to install Cython:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install Cython
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;PS:&lt;/strong&gt; Many Scientific distributions of Python (ie. Anaconda) already ships Cython.&lt;/p&gt;

&lt;h3 id=&#34;cython-in-programming-contests&#34;&gt;Cython in Programming Contests&lt;/h3&gt;

&lt;p&gt;Since we saw that Cython is super fast and easy to setup, programming contests can make Cython available
along with CPython to allow the contestants make their programs faster and get along with Java / C++.
It will make Python an attractive choice for serious problem solving.&lt;/p&gt;

&lt;p&gt;I know the &lt;code&gt;Cython&lt;/code&gt; language is not exactly Python. It is a superset of the Python language. So beginners might
not be familiar with the language and that&amp;rsquo;s alright. Beginners can start with Python and start solving the
easier problems with Python. When they start competitive programming and start hitting the time limits, then
Cython is one of the options they can choose to make their code run faster. Of course Cython needs some
understanding of how C works - that&amp;rsquo;s fine too because Cython still feels more productive than writing plain
old C or C++.&lt;/p&gt;

&lt;h3 id=&#34;final-words&#34;&gt;Final words&lt;/h3&gt;

&lt;p&gt;PyPy is already quite popular in the Python community. Dropbox and Microsoft are also working on their Python
JITs. I believe that someday Python JITs would be as fast as Java / C++.  Today, Python is making programming
fun for many beginners. I hope with Cython, we can worry less about the time limits and accept Python as a
fitting tool in our competitive programming contests!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Introduction to Django Channels</title>
      <link>http://masnun.rocks/2016/09/25/introduction-to-django-channels/</link>
      <pubDate>Sun, 25 Sep 2016 21:27:34 +0600</pubDate>
      
      <guid>http://masnun.rocks/2016/09/25/introduction-to-django-channels/</guid>
      <description>

&lt;p&gt;Django is a brilliant web framework. In fact it is my most favourite one for various reasons. An year and
a half ago, I switched to Python and Django for all my web development. I am a big fan of the eco system
and the many third party packages. Particularly I use Django REST Framework whenever I need to create
APIs. Having said that, Django was more than good enough for basic HTTP requests. But the web has changed.
We now have HTTP/2 and web sockets. Django could not support them well in the past. For the web socket part,
I usually had to rely on Tornado or NodeJS (with the excellent Socket.IO library). They are good technologies
but most of my web apps being in Django, I really wished there were something that could work with Django itself.
And then we had &lt;strong&gt;Channels&lt;/strong&gt;. The project is meant to allow Django to support HTTP/2, websockets or other
protocols with ease.&lt;/p&gt;

&lt;h3 id=&#34;concepts&#34;&gt;Concepts&lt;/h3&gt;

&lt;p&gt;The underlying concept is really simple - there are &lt;code&gt;channels&lt;/code&gt; and there are &lt;code&gt;messages&lt;/code&gt;,
there are &lt;code&gt;producers&lt;/code&gt; and there are &lt;code&gt;consumers&lt;/code&gt; - the whole system is based on passing messages
on to channels and consuming/responding to those messages.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s look at the core components of Django Channels first:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;channel&lt;/code&gt; - A channel is a FIFO queue like data structure. We can have many channels depending on our need.&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;message&lt;/code&gt; - A message contains meaningful data for the consumers. Messages are passed on to the channels.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;consumer&lt;/code&gt; - A consumer is usually a function that consumes a message and take actions.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;interface server&lt;/code&gt; - The interface server knows how to handle different protocols. It works as a translator
or a bridge between Django and the outside world.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;how-does-it-work&#34;&gt;How does it work?&lt;/h3&gt;

&lt;p&gt;A http request first comes to the &lt;code&gt;Interface Server&lt;/code&gt; which knows how to deal with a specific type of
request. For example, for websockets and http, &lt;strong&gt;Daphne&lt;/strong&gt; is a popular interface server. When a
new http/websocket request comes to the interface server (daphne in our case), it accepts the  request
and transforms it into a &lt;code&gt;message&lt;/code&gt;.  Then it passes the &lt;code&gt;message&lt;/code&gt; to the appropriate &lt;code&gt;channel&lt;/code&gt;. There are
predefined channels for specific types. For example, all http requests are passed to &lt;code&gt;http.request&lt;/code&gt; channel.
For incoming websocket messages, there is &lt;code&gt;websocket.receive&lt;/code&gt;. So these channels receive the messages when
the corresponding type of requests come in to the interface server.&lt;/p&gt;

&lt;p&gt;Now that we have &lt;code&gt;channels&lt;/code&gt; getting filled with &lt;code&gt;messages&lt;/code&gt;, we need a way to process these messages and
take actions (if necessary), right? Yes! For that we write some consumer functions and register them to
the channels we want. When messages come to these channels, the consumers are called with the message.
They can read the message and act on them.&lt;/p&gt;

&lt;p&gt;So far, we have seen how we can &lt;strong&gt;read&lt;/strong&gt; an incoming request. But like all web applications, we should
&lt;strong&gt;write&lt;/strong&gt; something back too, no? How do we do that? As it happens, the interface server is quite clever.
While transforming the incoming request into a message, it creates a &lt;code&gt;reply&lt;/code&gt; channel for that particular
client request and registers itself to that channel. Then it passes the reply channel along with the message.
When our consumer function reads the incoming message, it can pass a response to the &lt;code&gt;reply channel&lt;/code&gt; attached
with the message. Our interface server is listenning to that reply channel, remember? So when a response is sent
back to the reply channel, the interface server grabs the message, transforms it into a http response and sends
back to the client. Simple, no?&lt;/p&gt;

&lt;h3 id=&#34;writing-a-websocket-echo-server&#34;&gt;Writing a Websocket Echo Server&lt;/h3&gt;

&lt;p&gt;Enough with the theories, let&amp;rsquo;s get our hands dirty and build a simple echo server. The concept is simple.
The server accepts websocket connections, the client writes something to us, we just echo it back. Plain and
simple example.&lt;/p&gt;

&lt;h5 id=&#34;install-django-channels&#34;&gt;Install Django &amp;amp; Channels&lt;/h5&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pip install channels
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That should do the trick and install Django + Channels. Channels has Django as a depdency, so when you install
channels, Django comes with it.&lt;/p&gt;

&lt;h5 id=&#34;create-an-app&#34;&gt;Create An App&lt;/h5&gt;

&lt;p&gt;Next we create a new django project and app -&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;django-admin.py startproject djchan
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd djchan
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python manage.py startapp realtime
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;configure-installed-apps&#34;&gt;Configure &lt;code&gt;INSTALLED_APPS&lt;/code&gt;&lt;/h5&gt;

&lt;p&gt;We have our Django app ready. We need to add &lt;code&gt;channels&lt;/code&gt; and our django app (&lt;code&gt;realtime&lt;/code&gt;) to the &lt;code&gt;INSTALLED_APPS&lt;/code&gt; list under &lt;code&gt;settings.py&lt;/code&gt;.
Let&amp;rsquo;s do that:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;INSTALLED_APPS = [
    &#39;django.contrib.admin&#39;,
    &#39;django.contrib.auth&#39;,
    &#39;django.contrib.contenttypes&#39;,
    &#39;django.contrib.sessions&#39;,
    &#39;django.contrib.messages&#39;,
    &#39;django.contrib.staticfiles&#39;,

    &amp;quot;channels&amp;quot;,
    &amp;quot;realtime&amp;quot;
]
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;write-our-consumer&#34;&gt;Write our Consumer&lt;/h5&gt;

&lt;p&gt;After that, we need to start writing a consumer function that will process the incoming websocket messages
and send back the response:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# consumers.py 
def websocket_receive(message):
    text = message.content.get(&#39;text&#39;)
    if text:
        message.reply_channel.send({&amp;quot;text&amp;quot;: &amp;quot;You said: {}&amp;quot;.format(text)})

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The code is simple enough. We receieve a message, get it&amp;rsquo;s text content (we&amp;rsquo;re expecting that the websocket
connection will send only text data for this exmaple) and then push it back to the &lt;code&gt;reply_channel&lt;/code&gt; - just like
we planned.&lt;/p&gt;

&lt;h5 id=&#34;channels-routing&#34;&gt;Channels Routing&lt;/h5&gt;

&lt;p&gt;We have our consume function ready, now we need to tell Django how to route messages to our consumer. Just like
URL routing, we need to define our channel routings.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# routing.py
from channels.routing import route
from .consumers import websocket_receive
 
channel_routing = [
    route(&amp;quot;websocket.receive&amp;quot;, websocket_receive, path=r&amp;quot;^/chat/&amp;quot;),
]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The code should be self explanatory. We have a list of &lt;code&gt;route&lt;/code&gt; objects. Here we select the channel name
(&lt;code&gt;websocket.receive&lt;/code&gt; =&amp;gt; for receieving websocket messages), pass the consumer function and then configure
the optional &lt;code&gt;path&lt;/code&gt;. The path is an interesting bit. If we didn&amp;rsquo;t pass a value for it, the consumer will
get all the messages in the &lt;code&gt;websocket.receive&lt;/code&gt; channel on any URL. So if someone created a websocket connection
to &lt;code&gt;/&lt;/code&gt; or &lt;code&gt;/private&lt;/code&gt; or &lt;code&gt;/user/1234&lt;/code&gt; - regardless of the url path, we would get all incoming messages. But
that&amp;rsquo;s not our intention, right? So we restrict the &lt;code&gt;path&lt;/code&gt; to &lt;code&gt;/chat&lt;/code&gt; so only connections made to that url
are handled by the consumer. Please note the beginning &lt;code&gt;/&lt;/code&gt;, unlike url routing, in channels, we have to use it.&lt;/p&gt;

&lt;h5 id=&#34;configuring-the-channel-layers&#34;&gt;Configuring The Channel Layers&lt;/h5&gt;

&lt;p&gt;We have defined a consumer and added it to a routing table. We&amp;rsquo;re more or less ready. There&amp;rsquo;s just a final
bit of configuration we need to do. We need to tell channels two things - which backend we want to use and
where it can find our channel routing.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s briefly talk about the backend. The messages and the channels - Django needs some sort of data store or
message queue to back this system. By default Django can use in memory backend which keeps these things in memory
but if you consider a distributed app, for scaling large, you need something else. Redis is a popular and proven
piece of technology for these kinds of scenarios. In our case we would use the Redis backend.&lt;/p&gt;

&lt;p&gt;So let&amp;rsquo;s install that:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;pip install asgi_redis
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And now we put this in our &lt;code&gt;settings.py&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;CHANNEL_LAYERS = {
    &amp;quot;default&amp;quot;: {
        &amp;quot;BACKEND&amp;quot;: &amp;quot;asgi_redis.RedisChannelLayer&amp;quot;,
        &amp;quot;CONFIG&amp;quot;: {
            &amp;quot;hosts&amp;quot;: [(&amp;quot;localhost&amp;quot;, 6379)],
        },
        &amp;quot;ROUTING&amp;quot;: &amp;quot;realtime.routing.channel_routing&amp;quot;,
    },
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;running-the-servers&#34;&gt;Running The Servers&lt;/h5&gt;

&lt;p&gt;Make sure that Redis is running (usually &lt;code&gt;redis-server&lt;/code&gt; should run it). Now run the django app:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python manage.py runserver
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In local environment, when you do &lt;code&gt;runserver&lt;/code&gt; - Django launches both the interface server and necessary
 background workers (to run the consumer functions in the background). But in production,
 we should run the workers seperately. We will get to that soon.&lt;/p&gt;

&lt;h5 id=&#34;trying-it-out&#34;&gt;Trying it Out!&lt;/h5&gt;

&lt;p&gt;Once our dev server starts up, let’s open up the web app. If you haven’t added any django views,
no worries, you should still see the “It Worked!” welcome page of Django and that should be
fine for now. We need to test our websocket and we are smart enough to do that from the dev console.
Open up your Chrome Devtools (or Firefox | Safari | any other browser’s dev tools) and navigate to the
JS console. Paste the following JS code:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;
socket = new WebSocket(&amp;quot;ws://&amp;quot; + window.location.host + &amp;quot;/chat/&amp;quot;);
socket.onmessage = function(e) {
    alert(e.data);
}
socket.onopen = function() {
    socket.send(&amp;quot;hello world&amp;quot;);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If everything worked, you should get an alert with the message we sent. Since we defined a path,
the websocket connection works only on /chat/. Try modifying the JS code and send a message to
some other url to see how they don’t work. Also remove the path from our route and see how you can catch
all websocket messages from all the websocket connections regardless of which url they were connected to.
Cool, no?&lt;/p&gt;

&lt;h5 id=&#34;our-custom-channels&#34;&gt;Our Custom Channels&lt;/h5&gt;

&lt;p&gt;We have seen that certain protocols have predefined channels for various purposes. But we are not limited to those.
We can create our own channels. We don&amp;rsquo;t need to do anything fancy to initialize a new channel. We just need to
mention a name and send some messages to it. Django will create the channel for us.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;Channel(&amp;quot;thumbnailer&amp;quot;).send({
        &amp;quot;image_id&amp;quot;: image.id
    })
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Of course we need corresponding workers to be listenning to those channels. Otherwise nothing will happen.
Please note that besides working with new protocols, Channels also allow us to create some sort of message
based task queues. We create channels for certain tasks and our workers listen to those channels. Then we
pass the data to those channels and the workers process them. So for simpler tasks, this could be a nice
solution.&lt;/p&gt;

&lt;h3 id=&#34;scaling-production-systems&#34;&gt;Scaling Production Systems&lt;/h3&gt;

&lt;h5 id=&#34;running-workers-seperately&#34;&gt;Running Workers Seperately&lt;/h5&gt;

&lt;p&gt;On a production environment, we would want to run the workers seperately (since we would not run &lt;code&gt;runserver&lt;/code&gt; on
production anyway). To run the background workers, we have to run this command:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python manage.py runworker
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;asgi-daphne&#34;&gt;ASGI &amp;amp; Daphne&lt;/h5&gt;

&lt;p&gt;In our local environment, the &lt;code&gt;runserver&lt;/code&gt; command took care of launching the Interface server and background
workers. But now we have to run the interface server ourselves. We mentioned &lt;strong&gt;Daphne&lt;/strong&gt; already. It works
with the &lt;code&gt;ASGI&lt;/code&gt; standard (which is commonly used for HTTP/2 and websockets). Just like &lt;code&gt;wsgi.py&lt;/code&gt;, we now need to
create a &lt;code&gt;asgi.py&lt;/code&gt; module and configure it.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import os
from channels.asgi import get_channel_layer

os.environ.setdefault(&amp;quot;DJANGO_SETTINGS_MODULE&amp;quot;, &amp;quot;djchan.settings&amp;quot;)

channel_layer = get_channel_layer()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we can run the server:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;daphne djchan.asgi:channel_layer
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If everything goes right, the interface server should start running!&lt;/p&gt;

&lt;h5 id=&#34;asgi-or-wsgi&#34;&gt;ASGI or WSGI&lt;/h5&gt;

&lt;p&gt;ASGI is still new and WSGI is a battle tested http server. So you might still want to keep using wsgi for your
http only parts and asgi for the parts where you need channels specific features.&lt;/p&gt;

&lt;p&gt;The popular recommendation is that you should use &lt;code&gt;nginx&lt;/code&gt; or any other reverse proxies in front and route the
urls to asgi or uwsgi depending on the url or &lt;code&gt;Upgrade: WebSocket&lt;/code&gt; header.&lt;/p&gt;

&lt;h5 id=&#34;retries-and-celery&#34;&gt;Retries and Celery&lt;/h5&gt;

&lt;p&gt;The Channels system does not gurantee delivery. If there are tasks which needs the certainity, it is highly
recommended to use a system like Celery for these parts. Or we can also roll our own checks and retry logic if
we feel like that.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>About</title>
      <link>http://masnun.rocks/about/</link>
      <pubDate>Sun, 25 Sep 2016 11:20:58 +0600</pubDate>
      
      <guid>http://masnun.rocks/about/</guid>
      <description>

&lt;p&gt;I am a business graduate, *nix fan, open source enthusiast, fast learner, early adopter, team guy, explorer, deeply driven, self motivated software craftsman.&lt;/p&gt;

&lt;p&gt;I love music, hacking and playing urban terror. I contribute to open source projects at leisure. I would love to pursue challenging opportunities which contribute to a better tomorrow for all of us!&lt;/p&gt;

&lt;h2 id=&#34;what-is-in-my-skill-set&#34;&gt;What is in my skill set?&lt;/h2&gt;

&lt;p&gt;I am a &lt;strong&gt;full stack developer&lt;/strong&gt; with extensive experience in &lt;strong&gt;system administration&lt;/strong&gt;. I have played with a lot of tools and toys. However, I would call these my primary skills:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Python:&lt;/strong&gt; &lt;br/&gt;
You can call me a dedicated Python Developer. I love all things Python. I have 4 years of working experience with different Python tools and toys.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Django&lt;/li&gt;
&lt;li&gt;Django Rest Framework&lt;/li&gt;
&lt;li&gt;Flask&lt;/li&gt;
&lt;li&gt;Celery&lt;/li&gt;
&lt;li&gt;Scrapy&lt;/li&gt;
&lt;li&gt;BeautifulSoup&lt;/li&gt;
&lt;li&gt;Google App Engine&lt;/li&gt;
&lt;li&gt;Kivy&lt;/li&gt;
&lt;li&gt;PyQT / PySide&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;PHP:&lt;/strong&gt; &lt;br/&gt;
PHP has been my primary stack for a long time. I started doing professional PHP development since late 2008. I still enjoy writing PHP, specially with the new syntax, language features and modern frameworks - PHP is still fun to me.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Laravel&lt;/li&gt;
&lt;li&gt;Symfony&lt;/li&gt;
&lt;li&gt;Zend (1.x)&lt;/li&gt;
&lt;li&gt;Code Igniter&lt;/li&gt;
&lt;li&gt;WordPress&lt;/li&gt;
&lt;li&gt;Guzzle&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Front End:&lt;/strong&gt;&lt;br/&gt;
I have mostly worked as a backend developer during my career over the past 7-8 years. But I have had my share of front end development too. I am definitely &lt;strong&gt;not&lt;/strong&gt; a kickass front end ninja but I do know more than enough HTML, CSS and JavaScript to build decent Web UIs and mobile applications.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;JavaScript&lt;/li&gt;
&lt;li&gt;jQuery&lt;/li&gt;
&lt;li&gt;AngularJS (1.x)&lt;/li&gt;
&lt;li&gt;ReactJS&lt;/li&gt;
&lt;li&gt;Bootstrap&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I am learning &lt;code&gt;ES2015&lt;/code&gt; and beyond for writing cleaner codes.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tool Set:&lt;/strong&gt; &lt;br/&gt;
I know &lt;strong&gt;git&lt;/strong&gt; and work on &lt;strong&gt;OS X&lt;/strong&gt;. I have &lt;strong&gt;Linux VMs&lt;/strong&gt;  running inside &lt;strong&gt;Vagrant&lt;/strong&gt;. I am also a big fan of &lt;strong&gt;Docker&lt;/strong&gt; and find it a painless solution to develop and deploy my applications. I have working experience with &lt;strong&gt;MySQL&lt;/strong&gt;, &lt;strong&gt;PostgreSQL&lt;/strong&gt; and &lt;strong&gt;NoSQLs&lt;/strong&gt; as well. I have scored &lt;strong&gt;95%&lt;/strong&gt; in &lt;strong&gt;MongoDB&lt;/strong&gt; course from &lt;strong&gt;Mongo University&lt;/strong&gt;.  I will not only &lt;strong&gt;build&lt;/strong&gt; your app but also &lt;strong&gt;deploy&lt;/strong&gt; it to cloud providers like heroku, aws, rackspace or any VPS.&lt;/p&gt;

&lt;p&gt;I am a believer in &lt;strong&gt;code quality&lt;/strong&gt; and follow the best practices. I use &lt;strong&gt;Jetbrains IDEs&lt;/strong&gt; for optimum productivity and cleaner codes. I believe every developer should write &lt;strong&gt;unit tests&lt;/strong&gt; before starting to write business logic. &lt;strong&gt;BDD&lt;/strong&gt; and &lt;strong&gt;TDD&lt;/strong&gt; are my super secret ninja skills against bugs.&lt;/p&gt;

&lt;p&gt;While I am mostly focused on Python, PHP and Javascript, I love learning new technologies and adapt new tools to solve challenging problems. I have decent expertise in these tools too:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Node.js:&lt;/strong&gt;&lt;br/&gt;
I of course use Node.js as a part of my front end tooling but I also love building simple backends using it. I love the &lt;code&gt;npm&lt;/code&gt; package managers for it&amp;rsquo;s simplicity.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Express&lt;/li&gt;
&lt;li&gt;SailsJS&lt;/li&gt;
&lt;li&gt;MEAN&lt;/li&gt;
&lt;li&gt;Keystone JS&lt;/li&gt;
&lt;li&gt;&lt;code&gt;requests&lt;/code&gt; module for scraping&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br/&gt;
&lt;strong&gt;Redis:&lt;/strong&gt; I have used it as message queue, cache and data store.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Golang:&lt;/strong&gt; I am a big fan of it’s concurrency model, simple syntax and a nice standard library. I have written several command line tools in the language. Cross compilation and the &lt;code&gt;go fmt&lt;/code&gt; tool is a big plus for me.&lt;/p&gt;

&lt;h2 id=&#34;what-do-i-want-to-learn-next&#34;&gt;What do I want to learn next?&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Machine Learning&lt;/li&gt;
&lt;li&gt;Data Science&lt;/li&gt;
&lt;li&gt;Natural Language Processing&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;how-can-i-add-value-to-your-business&#34;&gt;How can I add value to your business?&lt;/h2&gt;

&lt;p&gt;I have a &lt;strong&gt;business degree&lt;/strong&gt; (and currently doing &lt;strong&gt;MBA&lt;/strong&gt;). I have a very keen interest in &lt;strong&gt;growth hacking&lt;/strong&gt;. I try to understand the business process and &lt;strong&gt;add values&lt;/strong&gt; to both customers and the business. I assume &lt;strong&gt;ownership&lt;/strong&gt; and &lt;strong&gt;lead by example&lt;/strong&gt;. I understand the importance of &lt;strong&gt;shipping fast&lt;/strong&gt; and capture the market before competitors. I think &lt;strong&gt;out of the box&lt;/strong&gt; and bring &lt;strong&gt;novelty&lt;/strong&gt; to the table.&lt;/p&gt;

&lt;p&gt;I translate the &lt;strong&gt;business requirements&lt;/strong&gt; into &lt;strong&gt;agile&lt;/strong&gt; software development practices and stride to achieve enhanced &lt;strong&gt;value creation&lt;/strong&gt; for all of us!&lt;/p&gt;

&lt;h2 id=&#34;community-engagement&#34;&gt;Community Engagement&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://pybd.org/&#34; target=&#34;_blank&#34;&gt;Python Bangladesh&lt;/a&gt;&lt;/li&gt;

&lt;li&gt;&lt;a href=&#34;https://www.facebook.com/groups/pxperts/&#34; target=&#34;_blank&#34;&gt;phpXperts&lt;/a&gt;&lt;/li&gt;

&lt;li&gt;&lt;a href=&#34;http://laravelbd.com&#34; target=&#34;_blank&#34;&gt;Laravel Bangladesh&lt;/a&gt;&lt;/li&gt;

&lt;li&gt;&lt;a href=&#34;http://talkjs.net/&#34; target=&#34;_blank&#34;&gt;Talk.js&lt;/a&gt;&lt;/li&gt;

&lt;li&gt;&lt;a href=&#34;https://www.facebook.com/groups/gofans/&#34; target=&#34;_blank&#34;&gt;Go Fans&lt;/a&gt;&lt;/li&gt;

&lt;li&gt;&lt;a href=&#34;http://gbgkhulna.org&#34; target=&#34;_blank&#34;&gt;Google Business Group Khulna&lt;/a&gt;&lt;/li&gt;

&lt;li&gt;&lt;a href=&#34;http://nodeschool.io/khulna/&#34; target=&#34;_blank&#34;&gt;NodeSchool Khulna&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Contact</title>
      <link>http://masnun.rocks/contact/</link>
      <pubDate>Sun, 25 Sep 2016 11:20:51 +0600</pubDate>
      
      <guid>http://masnun.rocks/contact/</guid>
      <description>&lt;hr/&gt;

&lt;p&gt;&lt;center&gt;&lt;b&gt;I usually prefer that you email me or leave me a message on Facebook.&lt;/b&gt;&lt;/center&gt;
&lt;hr/&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Email:&lt;/strong&gt; masnun [at] gmail.com &lt;br/&gt;
&lt;strong&gt;Skype:&lt;/strong&gt; masnun_ &lt;br/&gt;
&lt;strong&gt;Phone:&lt;/strong&gt; +880 1711 960803 &lt;small&gt;(I am in GMT +6, please call responsibly)&lt;/small&gt; &lt;br/&gt;
&lt;strong&gt;Facebook:&lt;/strong&gt; &lt;a href=&#34;http://facebook.com/masnun&#34;&gt;http://facebook.com/masnun&lt;/a&gt; &lt;br/&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>